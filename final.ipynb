{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import f\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from matplotlib import pyplot\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import keras\n",
    "import texthero as hero\n",
    "from texthero import preprocessing as str_preprocessing\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_and_bind(original_dataframe, feature_to_encode): # utility function for one-hot encoding\n",
    "    dummies = pd.get_dummies(original_dataframe[[feature_to_encode]])\n",
    "    res = pd.concat([original_dataframe, dummies], axis=1)\n",
    "    return(res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>geo_enabled</th>\n",
       "      <th>verified</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>contributors_enabled</th>\n",
       "      <th>profile_use_background_image</th>\n",
       "      <th>has_extended_profile</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>default_profile_image</th>\n",
       "      <th>following</th>\n",
       "      <th>follow_request_sent</th>\n",
       "      <th>notifications</th>\n",
       "      <th>bot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaseballQuotes1</td>\n",
       "      <td>The Diamond</td>\n",
       "      <td>Quoting America's Pastime in 280 characters or...</td>\n",
       "      <td>121500</td>\n",
       "      <td>346</td>\n",
       "      <td>532</td>\n",
       "      <td>35894</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>21246</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cavs</td>\n",
       "      <td>The Q | Cleveland, OH</td>\n",
       "      <td>Official Twitter of the 2016 NBA Champion Clev...</td>\n",
       "      <td>3227215</td>\n",
       "      <td>1946</td>\n",
       "      <td>9039</td>\n",
       "      <td>16134</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>45791</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>muohajer_12</td>\n",
       "      <td>ÿßŸÑŸÖŸÖŸÑŸÉÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ÿßŸÑÿ≥ÿπŸàÿØŸäÿ©</td>\n",
       "      <td></td>\n",
       "      <td>864968</td>\n",
       "      <td>767106</td>\n",
       "      <td>1371</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>875763</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bc20_</td>\n",
       "      <td></td>\n",
       "      <td>R.I.P JRL21//R.I.P Monicaüíô IG//b.20c #GLOHIOBOYS</td>\n",
       "      <td>951</td>\n",
       "      <td>275</td>\n",
       "      <td>9</td>\n",
       "      <td>22147</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>88862</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_Blkahontas</td>\n",
       "      <td>Hollywood, FL</td>\n",
       "      <td>to die for üîÆü§ûüèæüë∏üèæ</td>\n",
       "      <td>1412</td>\n",
       "      <td>623</td>\n",
       "      <td>12</td>\n",
       "      <td>5582</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>142073</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>BigMacFlashy</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "      <td>CEO of @thebambox and @comiconauction. Love De...</td>\n",
       "      <td>331</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>350</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>325</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>BadruulAminn</td>\n",
       "      <td>Petaling, Selangor</td>\n",
       "      <td>20 / YouTuber + Streamer / Married /\\n\\nCome s...</td>\n",
       "      <td>71105</td>\n",
       "      <td>62028</td>\n",
       "      <td>27</td>\n",
       "      <td>1818</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>27006</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>anxietyhes</td>\n",
       "      <td></td>\n",
       "      <td>woke up the girl who looked just like you I al...</td>\n",
       "      <td>99769</td>\n",
       "      <td>67170</td>\n",
       "      <td>335</td>\n",
       "      <td>27192</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>81781</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>EN_owl</td>\n",
       "      <td>„Å™„Åî„ÇÑ„Å°„Åª„Éº</td>\n",
       "      <td>ÊóßÂûã„ÇØ„É≠„Çπ„Ç´„ÉñÊîπ(„Éó„É©„Ç¶„ÉÄÊà¶ËªäËâ≤)„Å´‰πó„Çã„Ç¨„É´„Éë„É≥„Åä„Åò„Åï„Çì„ÄÇ„Éé„É≥„Éä„Å®ÊÑõÈáåÂØøÊé®„Åó„ÄÇÊó•Êú¨‰∏ÄÂë®201...</td>\n",
       "      <td>1222</td>\n",
       "      <td>244</td>\n",
       "      <td>102</td>\n",
       "      <td>382</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>70120</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>cessdomingo_</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1308</td>\n",
       "      <td>1017</td>\n",
       "      <td>0</td>\n",
       "      <td>39669</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>44078</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2502 rows √ó 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          screen_name                  location  \\\n",
       "0     BaseballQuotes1               The Diamond   \n",
       "1                cavs     The Q | Cleveland, OH   \n",
       "2         muohajer_12  ÿßŸÑŸÖŸÖŸÑŸÉÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ÿßŸÑÿ≥ÿπŸàÿØŸäÿ©   \n",
       "3               Bc20_                             \n",
       "4         _Blkahontas             Hollywood, FL   \n",
       "...               ...                       ...   \n",
       "2497     BigMacFlashy               Phoenix, AZ   \n",
       "2498     BadruulAminn        Petaling, Selangor   \n",
       "2499       anxietyhes                             \n",
       "2500           EN_owl                    „Å™„Åî„ÇÑ„Å°„Åª„Éº   \n",
       "2501     cessdomingo_                             \n",
       "\n",
       "                                            description  followers_count  \\\n",
       "0     Quoting America's Pastime in 280 characters or...           121500   \n",
       "1     Official Twitter of the 2016 NBA Champion Clev...          3227215   \n",
       "2                                                                 864968   \n",
       "3      R.I.P JRL21//R.I.P Monicaüíô IG//b.20c #GLOHIOBOYS              951   \n",
       "4                                      to die for üîÆü§ûüèæüë∏üèæ             1412   \n",
       "...                                                 ...              ...   \n",
       "2497  CEO of @thebambox and @comiconauction. Love De...              331   \n",
       "2498  20 / YouTuber + Streamer / Married /\\n\\nCome s...            71105   \n",
       "2499  woke up the girl who looked just like you I al...            99769   \n",
       "2500  ÊóßÂûã„ÇØ„É≠„Çπ„Ç´„ÉñÊîπ(„Éó„É©„Ç¶„ÉÄÊà¶ËªäËâ≤)„Å´‰πó„Çã„Ç¨„É´„Éë„É≥„Åä„Åò„Åï„Çì„ÄÇ„Éé„É≥„Éä„Å®ÊÑõÈáåÂØøÊé®„Åó„ÄÇÊó•Êú¨‰∏ÄÂë®201...             1222   \n",
       "2501                                                                1308   \n",
       "\n",
       "      friends_count  listed_count  favourites_count  geo_enabled  verified  \\\n",
       "0               346           532             35894         True     False   \n",
       "1              1946          9039             16134         True      True   \n",
       "2            767106          1371                23         True     False   \n",
       "3               275             9             22147         True     False   \n",
       "4               623            12              5582         True     False   \n",
       "...             ...           ...               ...          ...       ...   \n",
       "2497            154             1               350        False     False   \n",
       "2498          62028            27              1818        False     False   \n",
       "2499          67170           335             27192         True     False   \n",
       "2500            244           102               382        False     False   \n",
       "2501           1017             0             39669         True     False   \n",
       "\n",
       "      statuses_count  contributors_enabled  profile_use_background_image  \\\n",
       "0              21246                 False                         False   \n",
       "1              45791                 False                          True   \n",
       "2             875763                 False                          True   \n",
       "3              88862                 False                         False   \n",
       "4             142073                 False                          True   \n",
       "...              ...                   ...                           ...   \n",
       "2497             325                 False                         False   \n",
       "2498           27006                 False                          True   \n",
       "2499           81781                 False                          True   \n",
       "2500           70120                 False                          True   \n",
       "2501           44078                 False                          True   \n",
       "\n",
       "      has_extended_profile  default_profile  default_profile_image  following  \\\n",
       "0                    False            False                  False      False   \n",
       "1                    False            False                  False      False   \n",
       "2                    False             True                  False      False   \n",
       "3                     True            False                  False      False   \n",
       "4                    False            False                  False      False   \n",
       "...                    ...              ...                    ...        ...   \n",
       "2497                 False            False                  False      False   \n",
       "2498                  True            False                  False      False   \n",
       "2499                  True            False                  False      False   \n",
       "2500                 False            False                  False      False   \n",
       "2501                 False            False                  False      False   \n",
       "\n",
       "      follow_request_sent  notifications  bot  \n",
       "0                   False          False    0  \n",
       "1                   False          False    0  \n",
       "2                   False          False    1  \n",
       "3                   False          False    0  \n",
       "4                   False          False    0  \n",
       "...                   ...            ...  ...  \n",
       "2497                False          False    0  \n",
       "2498                False          False    0  \n",
       "2499                False          False    0  \n",
       "2500                False          False    1  \n",
       "2501                False          False    0  \n",
       "\n",
       "[2502 rows x 19 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv (\"./gilani-2017/gilani-2017.tsv\", sep = '\\t')\n",
    "labels['id'] = labels['461277906']\n",
    "df = pd.read_json(\"./gilani-2017/gilani-2017_tweets.json\")\n",
    "df = pd.json_normalize(df['user'])\n",
    "df.columns = df.columns.map(lambda x: x.split(\".\")[-1])\n",
    "df = pd.merge(df,labels,on='id')\n",
    "\n",
    "df = df.drop(['461277906', 'lang', 'is_translator', 'is_translation_enabled',  'profile_background_tile',  'profile_background_color', 'profile_background_image_url', 'time_zone', 'profile_background_image_url_https', 'id', 'created_at', 'profile_image_url', 'profile_image_url_https', 'utc_offset' , 'url', 'profile_banner_url','protected','name','translator_type', 'urls', 'id_str', 'profile_sidebar_border_color', 'profile_sidebar_fill_color', 'profile_text_color', 'profile_link_color'], axis = 1)\n",
    "df.bot = [1 if i == 'bot' else 0 for i in df.bot]\n",
    "df = df.dropna(axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.asarray(df.drop(['bot'], axis = 1))\n",
    "\n",
    "\n",
    "custom_pipeline = [str_preprocessing.fillna,\n",
    "                   str_preprocessing.remove_whitespace,\n",
    "                   str_preprocessing.remove_diacritics,\n",
    "                   str_preprocessing.remove_brackets\n",
    "                  ]\n",
    "\n",
    "string_cols = ['screen_name', 'location', 'description' ]\n",
    "for ftr in string_cols:\n",
    "    df[ftr] = hero.clean(df[ftr], custom_pipeline)\n",
    "\n",
    "ftrs = ['followers_count', 'friends_count', 'listed_count', 'favourites_count', 'statuses_count']\n",
    "for ftr in ftrs:\n",
    "    df[ftr] = (np.array(df[ftr]) - np.mean(df[ftr]))/max(df[ftr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_2/fbtf2s8s6l3679y1xrlyxs180000gn/T/ipykernel_26363/3583974078.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                 for i, doc in enumerate(df[ftr])]\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDoc2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     card2vec = [model.infer_vector((df[ftr][i].split(' '))) \n",
      "\u001b[0;32m~/miniconda3/envs/stonks/lib/python3.9/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, documents, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m         \u001b[0mreport_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'memory'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_retained_words'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m         self.trainables.prepare_weights(\n\u001b[0m\u001b[1;32m    938\u001b[0m             self.hs, self.negative, self.wv, self.docvecs, update=update)\n\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/stonks/lib/python3.9/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36mprepare_weights\u001b[0;34m(self, hs, negative, wv, docvecs, update)\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;31m# set initial input/projection and hidden weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocvecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/stonks/lib/python3.9/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36mreset_weights\u001b[0;34m(self, hs, negative, wv, docvecs, vocabulary)\u001b[0m\n\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDoc2VecTrainables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_doc_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/stonks/lib/python3.9/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mreset_weights\u001b[0;34m(self, hs, negative, wv)\u001b[0m\n\u001b[1;32m   1702\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1703\u001b[0m             \u001b[0;31m# construct deterministic seed from word AND seed argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1704\u001b[0;31m             \u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseeded_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex2word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1705\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1706\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mREAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/stonks/lib/python3.9/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mseeded_vector\u001b[0;34m(self, seed_string, vector_size)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0;31m# Note: built-in hash() may vary by Python version or even (in Py3.x) per launch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m         \u001b[0monce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhashfxn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_string\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xffffffff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0monce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ftr in string_cols: #vector encoding\n",
    "    tokens = [TaggedDocument(doc.split(' '), [i]) \n",
    "                for i, doc in enumerate(df[ftr])]\n",
    "    model = Doc2Vec(vector_size=64, window=2, min_count=1, workers=8, epochs = 40)\n",
    "    model.build_vocab(tokens)\n",
    "    model.train(tokens, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    card2vec = [model.infer_vector((df[ftr][i].split(' '))) \n",
    "            for i in range(0,len(df[ftr]))]\n",
    "    df[ftr] = card2vec\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      followers_count  friends_count  listed_count  favourites_count  \\\n",
      "0           -0.009569      -0.009499     -0.003988          0.024466   \n",
      "1            0.019473      -0.008751      0.010039          0.002166   \n",
      "2           -0.002617       0.348570     -0.002604         -0.016015   \n",
      "3           -0.010696      -0.009532     -0.004850          0.008952   \n",
      "4           -0.010692      -0.009369     -0.004845         -0.009742   \n",
      "...               ...            ...           ...               ...   \n",
      "2497        -0.010702      -0.009588     -0.004863         -0.015646   \n",
      "2498        -0.010040       0.019306     -0.004820         -0.013990   \n",
      "2499        -0.009772       0.021707     -0.004312          0.014646   \n",
      "2500        -0.010694      -0.009546     -0.004697         -0.015610   \n",
      "2501        -0.010693      -0.009185     -0.004865          0.028726   \n",
      "\n",
      "      geo_enabled  verified  statuses_count  contributors_enabled  \\\n",
      "0            True     False       -0.022961                 False   \n",
      "1            True      True       -0.014089                 False   \n",
      "2            True     False        0.285917                 False   \n",
      "3            True     False        0.001480                 False   \n",
      "4            True     False        0.020714                 False   \n",
      "...           ...       ...             ...                   ...   \n",
      "2497        False     False       -0.030523                 False   \n",
      "2498        False     False       -0.020879                 False   \n",
      "2499         True     False       -0.001080                 False   \n",
      "2500        False     False       -0.005295                 False   \n",
      "2501         True     False       -0.014708                 False   \n",
      "\n",
      "      profile_use_background_image  has_extended_profile  default_profile  \\\n",
      "0                            False                 False            False   \n",
      "1                             True                 False            False   \n",
      "2                             True                 False             True   \n",
      "3                            False                  True            False   \n",
      "4                             True                 False            False   \n",
      "...                            ...                   ...              ...   \n",
      "2497                         False                 False            False   \n",
      "2498                          True                  True            False   \n",
      "2499                          True                  True            False   \n",
      "2500                          True                 False            False   \n",
      "2501                          True                 False            False   \n",
      "\n",
      "      default_profile_image  following  follow_request_sent  notifications  \\\n",
      "0                     False      False                False          False   \n",
      "1                     False      False                False          False   \n",
      "2                     False      False                False          False   \n",
      "3                     False      False                False          False   \n",
      "4                     False      False                False          False   \n",
      "...                     ...        ...                  ...            ...   \n",
      "2497                  False      False                False          False   \n",
      "2498                  False      False                False          False   \n",
      "2499                  False      False                False          False   \n",
      "2500                  False      False                False          False   \n",
      "2501                  False      False                False          False   \n",
      "\n",
      "      bot  \n",
      "0       0  \n",
      "1       0  \n",
      "2       1  \n",
      "3       0  \n",
      "4       0  \n",
      "...   ...  \n",
      "2497    0  \n",
      "2498    0  \n",
      "2499    0  \n",
      "2500    1  \n",
      "2501    0  \n",
      "\n",
      "[2502 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "data = df.copy()\n",
    "data = data.drop(['screen_name', 'location', 'description'] ,axis = 1)\n",
    "print(data)\n",
    "ftr_count = len(data.keys())\n",
    "data = np.asarray(data.drop(['bot'], axis = 1))\n",
    "\n",
    "# idx =int(len(df)*.7) #70-30 split\n",
    "# X_train, X_test, Y_train, Y_test = np.array(data[:idx:]), np.array(data[idx:,:]), np.array(df.bot[:idx:]), np.array(df.bot[idx:,:])\n",
    "# X_train, X_test, Y_train, Y_test = np.array(data[:idx]), np.array(data[idx:]), np.array(df.bot[:idx]), np.array(df.bot[idx:])\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data, np.array(df.bot),test_size = 0.3, random_state = 78)\n",
    "X_train, X_test, Y_train, Y_test = X_train.astype(np.float), X_test.astype(np.float), Y_train.astype(np.float), Y_test.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC:  0.7163781624500666\n"
     ]
    }
   ],
   "source": [
    "#RANDOM FOREST\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators = 3, criterion = 'entropy')\n",
    "rf.fit(X_train, Y_train)\n",
    "y_predict_forest = rf.predict(X_test)\n",
    "y_predict_forest = [1 if i > 0.5 else 0 for i in y_predict_forest]\n",
    "print(\"ACC: \", sum([1 if i==j else 0  for i,j in zip(y_predict_forest,Y_test) ])/len(y_predict_forest))\n",
    "# print(classification_report(Y_test, y_predict_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:57:45] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426408905/work/src/learner.cc:576: \n",
      "Parameters: { \"verbose\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:57:46] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426408905/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ACC:  0.7683089214380826\n"
     ]
    }
   ],
   "source": [
    "#RANDOM FOREST WITH BOOSTING\n",
    "# Import the model we are using\n",
    "from xgboost import XGBRFClassifier\n",
    "rf = XGBRFClassifier(n_estimators=100, use_label_encoder=False, verbose = True)\n",
    "rf.fit(X_train, Y_train)\n",
    "y_predict_forest = rf.predict(X_test)\n",
    "y_predict_forest = [1 if i > 0.5 else 0 for i in y_predict_forest]\n",
    "\n",
    "print(\"ACC: \", sum([1 if i==j else 0  for i,j in zip(y_predict_forest,Y_test) ])/len(y_predict_forest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC:  0.6644474034620506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=100) # tuned to 100\n",
    "knn.fit(X_train, Y_train)\n",
    "y_predict_knn = knn.predict(X_test)\n",
    "y_predict_knn = [1 if i > 0.5 else 0 for i in y_predict_knn]\n",
    "print(\"ACC: \", sum([1 if i==j else 0  for i,j in zip(y_predict_knn,Y_test) ])/len(y_predict_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 32)                512       \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 32)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 64)                2112      \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 64)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " dropout_12 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " activation_15 (Activation)  (None, 64)                0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " activation_16 (Activation)  (None, 32)                0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      " activation_17 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,313\n",
      "Trainable params: 21,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#MODELS\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve,\n",
    "]\n",
    "\n",
    "def create_model(idim = ftr_count-1):\n",
    "  model = Sequential()\n",
    "\n",
    "  model.add(Dense(32, input_dim=idim))\n",
    "  model.add(Dropout(.3))\n",
    "  model.add(Activation('gelu'))\n",
    "\n",
    "  model.add(Dense(64, input_dim=32))\n",
    "  model.add(Dropout(.3))\n",
    "  model.add(Activation('gelu'))\n",
    "\n",
    "  model.add(Dense(128, input_dim=64))\n",
    "  model.add(Dropout(.5))\n",
    "  model.add(Activation('gelu'))\n",
    "\n",
    "\n",
    "  model.add(Dense(64, input_dim=128))\n",
    "  model.add(Dropout(.3))\n",
    "  model.add(Activation('gelu'))\n",
    "  \n",
    "  model.add(Dense(32, input_dim=64))\n",
    "  model.add(Dropout(.1))\n",
    "  model.add(Activation('gelu'))\n",
    "\n",
    "  model.add(Dense(1, input_dim=64))\n",
    "  model.add(Activation('sigmoid'))\n",
    "\n",
    "  optimizer = tf.keras.optimizers.SGD(\n",
    "    learning_rate=1e-3, nesterov=False,\n",
    "  )\n",
    "  #tfa.losses.SigmoidFocalCrossEntropy()\n",
    "  model.compile(optimizer = optimizer, loss= tf.keras.losses.BinaryCrossentropy(),  metrics=METRICS)\n",
    "  return model\n",
    "\n",
    "\n",
    "# class_weight = compute_class_weight(class_weight = 'balanced', classes = [0,1], y = np.array(df.bot).astype(np.float))\n",
    "# class_weight = {0: class_weight[0],\n",
    "#                 1: class_weight[1]}\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 0.6932 - tp: 322.0000 - fp: 421.0000 - tn: 530.0000 - fn: 383.0000 - accuracy: 0.5145 - precision: 0.4334 - recall: 0.4567 - auc: 0.5016 - prc: 0.4140\n",
      "Epoch 00001: val_loss improved from inf to 0.69332, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 5s 9ms/step - loss: 0.6932 - tp: 329.0000 - fp: 435.0000 - tn: 571.0000 - fn: 416.0000 - accuracy: 0.5140 - precision: 0.4306 - recall: 0.4416 - auc: 0.5015 - prc: 0.4135 - val_loss: 0.6933 - val_tp: 0.0000e+00 - val_fp: 2.0000 - val_tn: 405.0000 - val_fn: 344.0000 - val_accuracy: 0.5393 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4794 - val_prc: 0.4343 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.6914 - tp: 99.0000 - fp: 166.0000 - tn: 829.0000 - fn: 642.0000 - accuracy: 0.5346 - precision: 0.3736 - recall: 0.1336 - auc: 0.4786 - prc: 0.3988\n",
      "Epoch 00002: val_loss improved from 0.69332 to 0.69226, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.6914 - tp: 99.0000 - fp: 169.0000 - tn: 837.0000 - fn: 646.0000 - accuracy: 0.5346 - precision: 0.3694 - recall: 0.1329 - auc: 0.4772 - prc: 0.3963 - val_loss: 0.6923 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4276 - val_prc: 0.4147 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.6890 - tp: 35.0000 - fp: 70.0000 - tn: 914.0000 - fn: 701.0000 - accuracy: 0.5517 - precision: 0.3333 - recall: 0.0476 - auc: 0.5116 - prc: 0.4191       \n",
      "Epoch 00003: val_loss improved from 0.69226 to 0.69146, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6888 - tp: 36.0000 - fp: 71.0000 - tn: 935.0000 - fn: 709.0000 - accuracy: 0.5545 - precision: 0.3364 - recall: 0.0483 - auc: 0.5115 - prc: 0.4170 - val_loss: 0.6915 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3985 - val_prc: 0.3906 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.6883 - tp: 10.0000 - fp: 31.0000 - tn: 933.0000 - fn: 698.0000 - accuracy: 0.5640 - precision: 0.2439 - recall: 0.0141 - auc: 0.4892 - prc: 0.4015\n",
      "Epoch 00004: val_loss improved from 0.69146 to 0.69086, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6885 - tp: 10.0000 - fp: 32.0000 - tn: 974.0000 - fn: 735.0000 - accuracy: 0.5620 - precision: 0.2381 - recall: 0.0134 - auc: 0.4873 - prc: 0.4023 - val_loss: 0.6909 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.3884 - val_prc: 0.3844 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "205/219 [===========================>..] - ETA: 0s - loss: 0.6871 - tp: 3.0000 - fp: 12.0000 - tn: 927.0000 - fn: 698.0000 - accuracy: 0.5671 - precision: 0.2000 - recall: 0.0043 - auc: 0.4905 - prc: 0.4055\n",
      "Epoch 00005: val_loss improved from 0.69086 to 0.69043, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6870 - tp: 3.0000 - fp: 13.0000 - tn: 993.0000 - fn: 742.0000 - accuracy: 0.5688 - precision: 0.1875 - recall: 0.0040 - auc: 0.4882 - prc: 0.4024 - val_loss: 0.6904 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4375 - val_prc: 0.4107 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.6853 - tp: 0.0000e+00 - fp: 3.0000 - tn: 954.0000 - fn: 707.0000 - accuracy: 0.5733 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5136 - prc: 0.4134\n",
      "Epoch 00006: val_loss improved from 0.69043 to 0.69013, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.6854 - tp: 0.0000e+00 - fp: 3.0000 - tn: 1003.0000 - fn: 745.0000 - accuracy: 0.5728 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5128 - prc: 0.4133 - val_loss: 0.6901 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4007 - val_prc: 0.3928 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.6845 - tp: 1.0000 - fp: 3.0000 - tn: 960.0000 - fn: 708.0000 - accuracy: 0.5748 - precision: 0.2500 - recall: 0.0014 - auc: 0.5124 - prc: 0.4169   \n",
      "Epoch 00007: val_loss improved from 0.69013 to 0.68993, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6849 - tp: 1.0000 - fp: 3.0000 - tn: 1003.0000 - fn: 744.0000 - accuracy: 0.5734 - precision: 0.2500 - recall: 0.0013 - auc: 0.5080 - prc: 0.4165 - val_loss: 0.6899 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4605 - val_prc: 0.4314 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.6850 - tp: 0.0000e+00 - fp: 1.0000 - tn: 1005.0000 - fn: 745.0000 - accuracy: 0.5740 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4877 - prc: 0.4012 \n",
      "Epoch 00008: val_loss improved from 0.68993 to 0.68979, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6850 - tp: 0.0000e+00 - fp: 1.0000 - tn: 1005.0000 - fn: 745.0000 - accuracy: 0.5740 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4877 - prc: 0.4012 - val_loss: 0.6898 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4961 - val_prc: 0.4513 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.6842 - tp: 0.0000e+00 - fp: 1.0000 - tn: 1001.0000 - fn: 742.0000 - accuracy: 0.5740 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4983 - prc: 0.4035\n",
      "Epoch 00009: val_loss improved from 0.68979 to 0.68971, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6841 - tp: 0.0000e+00 - fp: 1.0000 - tn: 1005.0000 - fn: 745.0000 - accuracy: 0.5740 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4994 - prc: 0.4040 - val_loss: 0.6897 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4806 - val_prc: 0.4404 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "199/219 [==========================>...] - ETA: 0s - loss: 0.6849 - tp: 0.0000e+00 - fp: 1.0000 - tn: 906.0000 - fn: 685.0000 - accuracy: 0.5691 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4922 - prc: 0.4035 \n",
      "Epoch 00010: val_loss improved from 0.68971 to 0.68967, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6842 - tp: 0.0000e+00 - fp: 1.0000 - tn: 1005.0000 - fn: 745.0000 - accuracy: 0.5740 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.4882 - prc: 0.3973 - val_loss: 0.6897 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4830 - val_prc: 0.4470 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.6833 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 960.0000 - fn: 720.0000 - accuracy: 0.5714 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5129 - prc: 0.4168\n",
      "Epoch 00011: val_loss improved from 0.68967 to 0.68966, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6826 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5149 - prc: 0.4147 - val_loss: 0.6897 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.4873 - val_prc: 0.4431 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 0.6812 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 957.0000 - fn: 699.0000 - accuracy: 0.5779 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5191 - prc: 0.4150\n",
      "Epoch 00012: val_loss did not improve from 0.68966\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6823 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5130 - prc: 0.4153 - val_loss: 0.6897 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5320 - val_prc: 0.4829 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.6818 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5269 - prc: 0.4250\n",
      "Epoch 00013: val_loss did not improve from 0.68966\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6818 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5269 - prc: 0.4250 - val_loss: 0.6897 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5108 - val_prc: 0.4689 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "206/219 [===========================>..] - ETA: 0s - loss: 0.6819 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 949.0000 - fn: 699.0000 - accuracy: 0.5758 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5180 - prc: 0.4157\n",
      "Epoch 00014: val_loss did not improve from 0.68966\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.6821 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5175 - prc: 0.4165 - val_loss: 0.6897 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5238 - val_prc: 0.4677 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.6813 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 993.0000 - fn: 735.0000 - accuracy: 0.5747 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5323 - prc: 0.4305\n",
      "Epoch 00015: val_loss did not improve from 0.68966\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6813 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5332 - prc: 0.4311 - val_loss: 0.6898 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5449 - val_prc: 0.4966 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "213/219 [============================>.] - ETA: 0s - loss: 0.6820 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 976.0000 - fn: 728.0000 - accuracy: 0.5728 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5243 - prc: 0.4242\n",
      "Epoch 00016: val_loss did not improve from 0.68966\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6815 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5258 - prc: 0.4231 - val_loss: 0.6898 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5393 - val_prc: 0.4943 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.6809 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 995.0000 - fn: 733.0000 - accuracy: 0.5758 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5289 - prc: 0.4336\n",
      "Epoch 00017: val_loss did not improve from 0.68966\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6812 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5278 - prc: 0.4339 - val_loss: 0.6898 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5669 - val_prc: 0.4969 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.6809 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1003.0000 - fn: 741.0000 - accuracy: 0.5751 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5381 - prc: 0.4417\n",
      "Epoch 00018: val_loss did not improve from 0.68966\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6811 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5368 - prc: 0.4413 - val_loss: 0.6899 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5747 - val_prc: 0.5148 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.6814 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 988.0000 - fn: 732.0000 - accuracy: 0.5744 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5256 - prc: 0.4254\n",
      "Epoch 00019: val_loss did not improve from 0.68966\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6815 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5223 - prc: 0.4224 - val_loss: 0.6899 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5556 - val_prc: 0.5004 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "205/219 [===========================>..] - ETA: 0s - loss: 0.6826 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 933.0000 - fn: 707.0000 - accuracy: 0.5689 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5261 - prc: 0.4372\n",
      "Epoch 00020: val_loss did not improve from 0.68966\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.6813 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5224 - prc: 0.4289 - val_loss: 0.6899 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5498 - val_prc: 0.4989 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "203/219 [==========================>...] - ETA: 0s - loss: 0.6823 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 928.0000 - fn: 696.0000 - accuracy: 0.5714 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5229 - prc: 0.4328\n",
      "Epoch 00021: val_loss did not improve from 0.68966\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6813 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5264 - prc: 0.4301 - val_loss: 0.6900 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5732 - val_prc: 0.5257 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "206/219 [===========================>..] - ETA: 0s - loss: 0.6790 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 950.0000 - fn: 698.0000 - accuracy: 0.5765 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5612 - prc: 0.4508\n",
      "Epoch 00022: val_loss did not improve from 0.68966\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6794 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5634 - prc: 0.4552 - val_loss: 0.6900 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5845 - val_prc: 0.5191 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "205/219 [===========================>..] - ETA: 0s - loss: 0.6806 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 941.0000 - fn: 699.0000 - accuracy: 0.5738 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5432 - prc: 0.4400\n",
      "Epoch 00023: val_loss did not improve from 0.68966\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6806 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5371 - prc: 0.4343 - val_loss: 0.6900 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5775 - val_prc: 0.5123 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.6797 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 968.0000 - fn: 712.0000 - accuracy: 0.5762 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5483 - prc: 0.4376\n",
      "Epoch 00024: val_loss did not improve from 0.68966\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6803 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5447 - prc: 0.4367 - val_loss: 0.6900 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5927 - val_prc: 0.5285 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "203/219 [==========================>...] - ETA: 0s - loss: 0.6804 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 933.0000 - fn: 691.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5428 - prc: 0.4436\n",
      "Epoch 00025: val_loss did not improve from 0.68966\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.6806 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5381 - prc: 0.4399 - val_loss: 0.6900 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5909 - val_prc: 0.5280 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.6810 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5378 - prc: 0.4433\n",
      "Epoch 00026: val_loss did not improve from 0.68966\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6810 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5378 - prc: 0.4433 - val_loss: 0.6900 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5937 - val_prc: 0.5290 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "213/219 [============================>.] - ETA: 0s - loss: 0.6798 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 978.0000 - fn: 726.0000 - accuracy: 0.5739 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5542 - prc: 0.4528\n",
      "Epoch 00027: val_loss did not improve from 0.68966\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6797 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5510 - prc: 0.4504 - val_loss: 0.6899 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5946 - val_prc: 0.5321 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "206/219 [===========================>..] - ETA: 0s - loss: 0.6804 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 946.0000 - fn: 702.0000 - accuracy: 0.5740 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5481 - prc: 0.4472\n",
      "Epoch 00028: val_loss did not improve from 0.68966\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.6801 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5506 - prc: 0.4489 - val_loss: 0.6899 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6007 - val_prc: 0.5280 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.6813 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 998.0000 - fn: 738.0000 - accuracy: 0.5749 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5195 - prc: 0.4389\n",
      "Epoch 00029: val_loss did not improve from 0.68966\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6814 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5200 - prc: 0.4394 - val_loss: 0.6899 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5941 - val_prc: 0.5205 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.6779 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 976.0000 - fn: 712.0000 - accuracy: 0.5782 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5728 - prc: 0.4654\n",
      "Epoch 00030: val_loss did not improve from 0.68966\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.6792 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5704 - prc: 0.4683 - val_loss: 0.6899 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5990 - val_prc: 0.5255 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "204/219 [==========================>...] - ETA: 0s - loss: 0.6796 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 938.0000 - fn: 694.0000 - accuracy: 0.5748 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5533 - prc: 0.4473\n",
      "Epoch 00031: val_loss did not improve from 0.68966\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6797 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5537 - prc: 0.4500 - val_loss: 0.6899 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5896 - val_prc: 0.5218 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.6803 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1003.0000 - fn: 741.0000 - accuracy: 0.5751 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5374 - prc: 0.4380\n",
      "Epoch 00032: val_loss did not improve from 0.68966\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6805 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5372 - prc: 0.4386 - val_loss: 0.6898 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5934 - val_prc: 0.5229 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "202/219 [==========================>...] - ETA: 0s - loss: 0.6796 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 925.0000 - fn: 691.0000 - accuracy: 0.5724 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5662 - prc: 0.4626\n",
      "Epoch 00033: val_loss did not improve from 0.68966\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.6792 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5617 - prc: 0.4589 - val_loss: 0.6898 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5896 - val_prc: 0.5216 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "205/219 [===========================>..] - ETA: 0s - loss: 0.6785 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 947.0000 - fn: 693.0000 - accuracy: 0.5774 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5630 - prc: 0.4567- ETA: 0s - loss: 0.6760 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 591.0000 - fn: 417.0000 - accuracy: 0.5863 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5564 - prc - ETA: 0s - loss: 0.6784 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 943.0000 - fn: 689.0000 - accuracy: 0.5778 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5624 - prc: 0.456\n",
      "Epoch 00034: val_loss did not improve from 0.68966\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.6794 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5632 - prc: 0.4587 - val_loss: 0.6897 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5884 - val_prc: 0.5206 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.6804 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 984.0000 - fn: 728.0000 - accuracy: 0.5748 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5428 - prc: 0.4485\n",
      "Epoch 00035: val_loss did not improve from 0.68966\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6804 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5430 - prc: 0.4489 - val_loss: 0.6897 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5948 - val_prc: 0.5256 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.6796 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 968.0000 - fn: 720.0000 - accuracy: 0.5735 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5677 - prc: 0.4668\n",
      "Epoch 00036: val_loss improved from 0.68966 to 0.68965, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 3ms/step - loss: 0.6794 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5656 - prc: 0.4646 - val_loss: 0.6896 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6077 - val_prc: 0.5391 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 0.6794 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 956.0000 - fn: 700.0000 - accuracy: 0.5773 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5384 - prc: 0.4405\n",
      "Epoch 00037: val_loss improved from 0.68965 to 0.68958, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6801 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5429 - prc: 0.4475 - val_loss: 0.6896 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6063 - val_prc: 0.5384 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.6807 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 953.0000 - fn: 711.0000 - accuracy: 0.5727 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5489 - prc: 0.4558\n",
      "Epoch 00038: val_loss improved from 0.68958 to 0.68952, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6800 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5510 - prc: 0.4537 - val_loss: 0.6895 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6061 - val_prc: 0.5369 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.6781 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 970.0000 - fn: 710.0000 - accuracy: 0.5774 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5698 - prc: 0.4569\n",
      "Epoch 00039: val_loss improved from 0.68952 to 0.68946, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6791 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5681 - prc: 0.4598 - val_loss: 0.6895 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6028 - val_prc: 0.5386 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "213/219 [============================>.] - ETA: 0s - loss: 0.6782 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 981.0000 - fn: 723.0000 - accuracy: 0.5757 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5813 - prc: 0.4755\n",
      "Epoch 00040: val_loss improved from 0.68946 to 0.68942, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.6783 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5862 - prc: 0.4802 - val_loss: 0.6894 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5982 - val_prc: 0.5336 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "213/219 [============================>.] - ETA: 0s - loss: 0.6785 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 980.0000 - fn: 724.0000 - accuracy: 0.5751 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5708 - prc: 0.4684\n",
      "Epoch 00041: val_loss improved from 0.68942 to 0.68934, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.6788 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5709 - prc: 0.4683 - val_loss: 0.6893 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6000 - val_prc: 0.5359 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.6793 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 971.0000 - fn: 717.0000 - accuracy: 0.5752 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5450 - prc: 0.4431\n",
      "Epoch 00042: val_loss improved from 0.68934 to 0.68927, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6793 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5489 - prc: 0.4463 - val_loss: 0.6893 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6005 - val_prc: 0.5366 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "203/219 [==========================>...] - ETA: 0s - loss: 0.6786 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 938.0000 - fn: 686.0000 - accuracy: 0.5776 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5598 - prc: 0.4560\n",
      "Epoch 00043: val_loss improved from 0.68927 to 0.68920, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6792 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5655 - prc: 0.4618 - val_loss: 0.6892 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6205 - val_prc: 0.5450 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.6798 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 968.0000 - fn: 720.0000 - accuracy: 0.5735 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5562 - prc: 0.4585\n",
      "Epoch 00044: val_loss improved from 0.68920 to 0.68912, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.6794 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5568 - prc: 0.4586 - val_loss: 0.6891 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6236 - val_prc: 0.5478 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.6787 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5607 - prc: 0.4581\n",
      "Epoch 00045: val_loss improved from 0.68912 to 0.68906, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6787 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5607 - prc: 0.4581 - val_loss: 0.6891 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6248 - val_prc: 0.5523 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "203/219 [==========================>...] - ETA: 0s - loss: 0.6814 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 925.0000 - fn: 699.0000 - accuracy: 0.5696 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5426 - prc: 0.4412\n",
      "Epoch 00046: val_loss improved from 0.68906 to 0.68900, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6798 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5468 - prc: 0.4399 - val_loss: 0.6890 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6319 - val_prc: 0.5605 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.6795 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 966.0000 - fn: 722.0000 - accuracy: 0.5723 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5658 - prc: 0.4688\n",
      "Epoch 00047: val_loss improved from 0.68900 to 0.68893, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6788 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5654 - prc: 0.4672 - val_loss: 0.6889 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6267 - val_prc: 0.5637 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "203/219 [==========================>...] - ETA: 0s - loss: 0.6801 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 928.0000 - fn: 696.0000 - accuracy: 0.5714 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5611 - prc: 0.4570\n",
      "Epoch 00048: val_loss improved from 0.68893 to 0.68885, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6790 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5636 - prc: 0.4569 - val_loss: 0.6889 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6239 - val_prc: 0.5534 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.6776 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 962.0000 - fn: 710.0000 - accuracy: 0.5754 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5870 - prc: 0.4940\n",
      "Epoch 00049: val_loss improved from 0.68885 to 0.68878, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6780 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5857 - prc: 0.4906 - val_loss: 0.6888 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6229 - val_prc: 0.5515 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "213/219 [============================>.] - ETA: 0s - loss: 0.6793 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 975.0000 - fn: 729.0000 - accuracy: 0.5722 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5660 - prc: 0.4710\n",
      "Epoch 00050: val_loss improved from 0.68878 to 0.68872, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.6783 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5704 - prc: 0.4735 - val_loss: 0.6887 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6271 - val_prc: 0.5553 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(x=X_train.astype(np.float), y=Y_train.astype(np.float), batch_size=8, epochs=50, validation_data=(X_test.astype(np.float), Y_test.astype(np.float)), verbose=1, shuffle=True, callbacks=\n",
    "                                [ModelCheckpoint(filepath='./ckpts/best_val_loss.hdf5',\n",
    "                                               monitor= 'val_loss',\n",
    "                                               save_best_only=True,\n",
    "                                               mode='auto',\n",
    "                                               save_weights_only=True,\n",
    "                                               verbose=2),\n",
    "                                EarlyStopping(monitor='val_loss',\n",
    "                                             mode='auto',\n",
    "                                             patience=100,\n",
    "                                             verbose=1),  \n",
    "                                ReduceLROnPlateau(\n",
    "                                monitor='loss', factor=0.1, patience=10, verbose=1,\n",
    "                                mode='auto', min_delta=0.0001, cooldown=0, min_lr=0\n",
    "                            )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[210]])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['loss']\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='val')\n",
    "pyplot.xlabel(\"Epochs\")\n",
    "pyplot.ylabel(\"Loss\")\n",
    "pyplot.title(\"Training and Validation Loss Over %d Epochs\" % (len(history.history['loss']),))\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "\n",
    "history.history['accuracy']\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='val')\n",
    "pyplot.xlabel(\"Epochs\")\n",
    "pyplot.ylabel(\"Accuracy\")\n",
    "pyplot.title(\"Training and Validation Accuracy Over %d Epochs\" % (len(history.history['loss']),))\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    " \n",
    "from sklearn.metrics import log_loss # The data is binary\n",
    "from math import sqrt\n",
    "\n",
    "model.built = True\n",
    "model.load_weights(\"ckpts/best_val_loss.hdf5\")\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = [1 if i > 0.5 else 0 for i in y_pred] # roc curve when you change threshold\n",
    "confusion_matrix(y_pred, Y_test)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cc4240bb6330fdaa0e5b1d4f2184411e5109cd7a3e886f36b28dcc715df5a2e5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('stonks': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
