{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import f\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from matplotlib import pyplot\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import keras\n",
    "import texthero as hero\n",
    "from texthero import preprocessing as str_preprocessing\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_and_bind(original_dataframe, feature_to_encode): # utility function for one-hot encoding\n",
    "    dummies = pd.get_dummies(original_dataframe[[feature_to_encode]])\n",
    "    res = pd.concat([original_dataframe, dummies], axis=1)\n",
    "    return(res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>geo_enabled</th>\n",
       "      <th>verified</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>contributors_enabled</th>\n",
       "      <th>profile_use_background_image</th>\n",
       "      <th>has_extended_profile</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>default_profile_image</th>\n",
       "      <th>following</th>\n",
       "      <th>follow_request_sent</th>\n",
       "      <th>notifications</th>\n",
       "      <th>bot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaseballQuotes1</td>\n",
       "      <td>The Diamond</td>\n",
       "      <td>Quoting America's Pastime in 280 characters or...</td>\n",
       "      <td>121500</td>\n",
       "      <td>346</td>\n",
       "      <td>532</td>\n",
       "      <td>35894</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>21246</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cavs</td>\n",
       "      <td>The Q | Cleveland, OH</td>\n",
       "      <td>Official Twitter of the 2016 NBA Champion Clev...</td>\n",
       "      <td>3227215</td>\n",
       "      <td>1946</td>\n",
       "      <td>9039</td>\n",
       "      <td>16134</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>45791</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>muohajer_12</td>\n",
       "      <td>ÿßŸÑŸÖŸÖŸÑŸÉÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ÿßŸÑÿ≥ÿπŸàÿØŸäÿ©</td>\n",
       "      <td></td>\n",
       "      <td>864968</td>\n",
       "      <td>767106</td>\n",
       "      <td>1371</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>875763</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bc20_</td>\n",
       "      <td></td>\n",
       "      <td>R.I.P JRL21//R.I.P Monicaüíô IG//b.20c #GLOHIOBOYS</td>\n",
       "      <td>951</td>\n",
       "      <td>275</td>\n",
       "      <td>9</td>\n",
       "      <td>22147</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>88862</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_Blkahontas</td>\n",
       "      <td>Hollywood, FL</td>\n",
       "      <td>to die for üîÆü§ûüèæüë∏üèæ</td>\n",
       "      <td>1412</td>\n",
       "      <td>623</td>\n",
       "      <td>12</td>\n",
       "      <td>5582</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>142073</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>BigMacFlashy</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "      <td>CEO of @thebambox and @comiconauction. Love De...</td>\n",
       "      <td>331</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>350</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>325</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>BadruulAminn</td>\n",
       "      <td>Petaling, Selangor</td>\n",
       "      <td>20 / YouTuber + Streamer / Married /\\n\\nCome s...</td>\n",
       "      <td>71105</td>\n",
       "      <td>62028</td>\n",
       "      <td>27</td>\n",
       "      <td>1818</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>27006</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>anxietyhes</td>\n",
       "      <td></td>\n",
       "      <td>woke up the girl who looked just like you I al...</td>\n",
       "      <td>99769</td>\n",
       "      <td>67170</td>\n",
       "      <td>335</td>\n",
       "      <td>27192</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>81781</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>EN_owl</td>\n",
       "      <td>„Å™„Åî„ÇÑ„Å°„Åª„Éº</td>\n",
       "      <td>ÊóßÂûã„ÇØ„É≠„Çπ„Ç´„ÉñÊîπ(„Éó„É©„Ç¶„ÉÄÊà¶ËªäËâ≤)„Å´‰πó„Çã„Ç¨„É´„Éë„É≥„Åä„Åò„Åï„Çì„ÄÇ„Éé„É≥„Éä„Å®ÊÑõÈáåÂØøÊé®„Åó„ÄÇÊó•Êú¨‰∏ÄÂë®201...</td>\n",
       "      <td>1222</td>\n",
       "      <td>244</td>\n",
       "      <td>102</td>\n",
       "      <td>382</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>70120</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>cessdomingo_</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1308</td>\n",
       "      <td>1017</td>\n",
       "      <td>0</td>\n",
       "      <td>39669</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>44078</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2502 rows √ó 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          screen_name                  location  \\\n",
       "0     BaseballQuotes1               The Diamond   \n",
       "1                cavs     The Q | Cleveland, OH   \n",
       "2         muohajer_12  ÿßŸÑŸÖŸÖŸÑŸÉÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ÿßŸÑÿ≥ÿπŸàÿØŸäÿ©   \n",
       "3               Bc20_                             \n",
       "4         _Blkahontas             Hollywood, FL   \n",
       "...               ...                       ...   \n",
       "2497     BigMacFlashy               Phoenix, AZ   \n",
       "2498     BadruulAminn        Petaling, Selangor   \n",
       "2499       anxietyhes                             \n",
       "2500           EN_owl                    „Å™„Åî„ÇÑ„Å°„Åª„Éº   \n",
       "2501     cessdomingo_                             \n",
       "\n",
       "                                            description  followers_count  \\\n",
       "0     Quoting America's Pastime in 280 characters or...           121500   \n",
       "1     Official Twitter of the 2016 NBA Champion Clev...          3227215   \n",
       "2                                                                 864968   \n",
       "3      R.I.P JRL21//R.I.P Monicaüíô IG//b.20c #GLOHIOBOYS              951   \n",
       "4                                      to die for üîÆü§ûüèæüë∏üèæ             1412   \n",
       "...                                                 ...              ...   \n",
       "2497  CEO of @thebambox and @comiconauction. Love De...              331   \n",
       "2498  20 / YouTuber + Streamer / Married /\\n\\nCome s...            71105   \n",
       "2499  woke up the girl who looked just like you I al...            99769   \n",
       "2500  ÊóßÂûã„ÇØ„É≠„Çπ„Ç´„ÉñÊîπ(„Éó„É©„Ç¶„ÉÄÊà¶ËªäËâ≤)„Å´‰πó„Çã„Ç¨„É´„Éë„É≥„Åä„Åò„Åï„Çì„ÄÇ„Éé„É≥„Éä„Å®ÊÑõÈáåÂØøÊé®„Åó„ÄÇÊó•Êú¨‰∏ÄÂë®201...             1222   \n",
       "2501                                                                1308   \n",
       "\n",
       "      friends_count  listed_count  favourites_count  geo_enabled  verified  \\\n",
       "0               346           532             35894         True     False   \n",
       "1              1946          9039             16134         True      True   \n",
       "2            767106          1371                23         True     False   \n",
       "3               275             9             22147         True     False   \n",
       "4               623            12              5582         True     False   \n",
       "...             ...           ...               ...          ...       ...   \n",
       "2497            154             1               350        False     False   \n",
       "2498          62028            27              1818        False     False   \n",
       "2499          67170           335             27192         True     False   \n",
       "2500            244           102               382        False     False   \n",
       "2501           1017             0             39669         True     False   \n",
       "\n",
       "      statuses_count  contributors_enabled  profile_use_background_image  \\\n",
       "0              21246                 False                         False   \n",
       "1              45791                 False                          True   \n",
       "2             875763                 False                          True   \n",
       "3              88862                 False                         False   \n",
       "4             142073                 False                          True   \n",
       "...              ...                   ...                           ...   \n",
       "2497             325                 False                         False   \n",
       "2498           27006                 False                          True   \n",
       "2499           81781                 False                          True   \n",
       "2500           70120                 False                          True   \n",
       "2501           44078                 False                          True   \n",
       "\n",
       "      has_extended_profile  default_profile  default_profile_image  following  \\\n",
       "0                    False            False                  False      False   \n",
       "1                    False            False                  False      False   \n",
       "2                    False             True                  False      False   \n",
       "3                     True            False                  False      False   \n",
       "4                    False            False                  False      False   \n",
       "...                    ...              ...                    ...        ...   \n",
       "2497                 False            False                  False      False   \n",
       "2498                  True            False                  False      False   \n",
       "2499                  True            False                  False      False   \n",
       "2500                 False            False                  False      False   \n",
       "2501                 False            False                  False      False   \n",
       "\n",
       "      follow_request_sent  notifications  bot  \n",
       "0                   False          False    0  \n",
       "1                   False          False    0  \n",
       "2                   False          False    1  \n",
       "3                   False          False    0  \n",
       "4                   False          False    0  \n",
       "...                   ...            ...  ...  \n",
       "2497                False          False    0  \n",
       "2498                False          False    0  \n",
       "2499                False          False    0  \n",
       "2500                False          False    1  \n",
       "2501                False          False    0  \n",
       "\n",
       "[2502 rows x 19 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv (\"./gilani-2017/gilani-2017.tsv\", sep = '\\t')\n",
    "labels['id'] = labels['461277906']\n",
    "df = pd.read_json(\"./gilani-2017/gilani-2017_tweets.json\")\n",
    "df = pd.json_normalize(df['user'])\n",
    "df.columns = df.columns.map(lambda x: x.split(\".\")[-1])\n",
    "df = pd.merge(df,labels,on='id')\n",
    "\n",
    "df = df.drop(['461277906', 'lang', 'is_translator', 'is_translation_enabled',  'profile_background_tile',  'profile_background_color', 'profile_background_image_url', 'time_zone', 'profile_background_image_url_https', 'id', 'created_at', 'profile_image_url', 'profile_image_url_https', 'utc_offset' , 'url', 'profile_banner_url','protected','name','translator_type', 'urls', 'id_str', 'profile_sidebar_border_color', 'profile_sidebar_fill_color', 'profile_text_color', 'profile_link_color'], axis = 1)\n",
    "df.bot = [1 if i == 'bot' else 0 for i in df.bot]\n",
    "df = df.dropna(axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.asarray(df.drop(['bot'], axis = 1))\n",
    "\n",
    "\n",
    "custom_pipeline = [str_preprocessing.fillna,\n",
    "                   str_preprocessing.remove_whitespace,\n",
    "                   str_preprocessing.remove_diacritics,\n",
    "                   str_preprocessing.remove_brackets\n",
    "                  ]\n",
    "\n",
    "string_cols = ['screen_name', 'location', 'description' ]\n",
    "for ftr in string_cols:\n",
    "    df[ftr] = hero.clean(df[ftr], custom_pipeline)\n",
    "\n",
    "ftrs = ['followers_count', 'friends_count', 'listed_count', 'favourites_count', 'statuses_count']\n",
    "for ftr in ftrs:\n",
    "    df[ftr] = (np.array(df[ftr]) - np.mean(df[ftr]))/max(df[ftr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_2/fbtf2s8s6l3679y1xrlyxs180000gn/T/ipykernel_26363/3583974078.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                 for i, doc in enumerate(df[ftr])]\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDoc2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_vocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     card2vec = [model.infer_vector((df[ftr][i].split(' '))) \n",
      "\u001b[0;32m~/miniconda3/envs/stonks/lib/python3.9/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36mbuild_vocab\u001b[0;34m(self, documents, corpus_file, update, progress_per, keep_raw_vocab, trim_rule, **kwargs)\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m         \u001b[0mreport_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'memory'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_retained_words'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m         self.trainables.prepare_weights(\n\u001b[0m\u001b[1;32m    938\u001b[0m             self.hs, self.negative, self.wv, self.docvecs, update=update)\n\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/stonks/lib/python3.9/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36mprepare_weights\u001b[0;34m(self, hs, negative, wv, docvecs, update)\u001b[0m\n\u001b[1;32m   1187\u001b[0m         \u001b[0;31m# set initial input/projection and hidden weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocvecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/stonks/lib/python3.9/site-packages/gensim/models/doc2vec.py\u001b[0m in \u001b[0;36mreset_weights\u001b[0;34m(self, hs, negative, wv, docvecs, vocabulary)\u001b[0m\n\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocvecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDoc2VecTrainables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_doc_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocvecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/stonks/lib/python3.9/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mreset_weights\u001b[0;34m(self, hs, negative, wv)\u001b[0m\n\u001b[1;32m   1702\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1703\u001b[0m             \u001b[0;31m# construct deterministic seed from word AND seed argument\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1704\u001b[0;31m             \u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseeded_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex2word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1705\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1706\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mREAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/stonks/lib/python3.9/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mseeded_vector\u001b[0;34m(self, seed_string, vector_size)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0;31m# Note: built-in hash() may vary by Python version or even (in Py3.x) per launch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m         \u001b[0monce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhashfxn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed_string\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xffffffff\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0monce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mvector_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for ftr in string_cols: #vector encoding\n",
    "    tokens = [TaggedDocument(doc.split(' '), [i]) \n",
    "                for i, doc in enumerate(df[ftr])]\n",
    "    model = Doc2Vec(vector_size=64, window=2, min_count=1, workers=8, epochs = 40)\n",
    "    model.build_vocab(tokens)\n",
    "    model.train(tokens, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    card2vec = [model.infer_vector((df[ftr][i].split(' '))) \n",
    "            for i in range(0,len(df[ftr]))]\n",
    "    df[ftr] = card2vec\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      followers_count  friends_count  listed_count  favourites_count  \\\n",
      "0           -0.009569      -0.009499     -0.003988          0.024466   \n",
      "1            0.019473      -0.008751      0.010039          0.002166   \n",
      "2           -0.002617       0.348570     -0.002604         -0.016015   \n",
      "3           -0.010696      -0.009532     -0.004850          0.008952   \n",
      "4           -0.010692      -0.009369     -0.004845         -0.009742   \n",
      "...               ...            ...           ...               ...   \n",
      "2497        -0.010702      -0.009588     -0.004863         -0.015646   \n",
      "2498        -0.010040       0.019306     -0.004820         -0.013990   \n",
      "2499        -0.009772       0.021707     -0.004312          0.014646   \n",
      "2500        -0.010694      -0.009546     -0.004697         -0.015610   \n",
      "2501        -0.010693      -0.009185     -0.004865          0.028726   \n",
      "\n",
      "      geo_enabled  verified  statuses_count  contributors_enabled  \\\n",
      "0            True     False       -0.022961                 False   \n",
      "1            True      True       -0.014089                 False   \n",
      "2            True     False        0.285917                 False   \n",
      "3            True     False        0.001480                 False   \n",
      "4            True     False        0.020714                 False   \n",
      "...           ...       ...             ...                   ...   \n",
      "2497        False     False       -0.030523                 False   \n",
      "2498        False     False       -0.020879                 False   \n",
      "2499         True     False       -0.001080                 False   \n",
      "2500        False     False       -0.005295                 False   \n",
      "2501         True     False       -0.014708                 False   \n",
      "\n",
      "      profile_use_background_image  has_extended_profile  default_profile  \\\n",
      "0                            False                 False            False   \n",
      "1                             True                 False            False   \n",
      "2                             True                 False             True   \n",
      "3                            False                  True            False   \n",
      "4                             True                 False            False   \n",
      "...                            ...                   ...              ...   \n",
      "2497                         False                 False            False   \n",
      "2498                          True                  True            False   \n",
      "2499                          True                  True            False   \n",
      "2500                          True                 False            False   \n",
      "2501                          True                 False            False   \n",
      "\n",
      "      default_profile_image  following  follow_request_sent  notifications  \\\n",
      "0                     False      False                False          False   \n",
      "1                     False      False                False          False   \n",
      "2                     False      False                False          False   \n",
      "3                     False      False                False          False   \n",
      "4                     False      False                False          False   \n",
      "...                     ...        ...                  ...            ...   \n",
      "2497                  False      False                False          False   \n",
      "2498                  False      False                False          False   \n",
      "2499                  False      False                False          False   \n",
      "2500                  False      False                False          False   \n",
      "2501                  False      False                False          False   \n",
      "\n",
      "      bot  \n",
      "0       0  \n",
      "1       0  \n",
      "2       1  \n",
      "3       0  \n",
      "4       0  \n",
      "...   ...  \n",
      "2497    0  \n",
      "2498    0  \n",
      "2499    0  \n",
      "2500    1  \n",
      "2501    0  \n",
      "\n",
      "[2502 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "data = df.copy()\n",
    "data = data.drop(['screen_name', 'location', 'description'] ,axis = 1)\n",
    "print(data)\n",
    "ftr_count = len(data.keys())\n",
    "data = np.asarray(data.drop(['bot'], axis = 1))\n",
    "\n",
    "# idx =int(len(df)*.7) #70-30 split\n",
    "# X_train, X_test, Y_train, Y_test = np.array(data[:idx:]), np.array(data[idx:,:]), np.array(df.bot[:idx:]), np.array(df.bot[idx:,:])\n",
    "# X_train, X_test, Y_train, Y_test = np.array(data[:idx]), np.array(data[idx:]), np.array(df.bot[:idx]), np.array(df.bot[idx:])\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data, np.array(df.bot),test_size = 0.3, random_state = 78)\n",
    "X_train, X_test, Y_train, Y_test = X_train.astype(np.float), X_test.astype(np.float), Y_train.astype(np.float), Y_test.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC:  0.7163781624500666\n"
     ]
    }
   ],
   "source": [
    "#RANDOM FOREST\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators = 3, criterion = 'entropy')\n",
    "rf.fit(X_train, Y_train)\n",
    "y_predict_forest = rf.predict(X_test)\n",
    "y_predict_forest = [1 if i > 0.5 else 0 for i in y_predict_forest]\n",
    "print(\"ACC: \", sum([1 if i==j else 0  for i,j in zip(y_predict_forest,Y_test) ])/len(y_predict_forest))\n",
    "# print(classification_report(Y_test, y_predict_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:57:45] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426408905/work/src/learner.cc:576: \n",
      "Parameters: { \"verbose\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[16:57:46] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1637426408905/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ACC:  0.7683089214380826\n"
     ]
    }
   ],
   "source": [
    "#RANDOM FOREST WITH BOOSTING\n",
    "# Import the model we are using\n",
    "from xgboost import XGBRFClassifier\n",
    "rf = XGBRFClassifier(n_estimators=100, use_label_encoder=False, verbose = True)\n",
    "rf.fit(X_train, Y_train)\n",
    "y_predict_forest = rf.predict(X_test)\n",
    "y_predict_forest = [1 if i > 0.5 else 0 for i in y_predict_forest]\n",
    "\n",
    "print(\"ACC: \", sum([1 if i==j else 0  for i,j in zip(y_predict_forest,Y_test) ])/len(y_predict_forest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC:  0.6644474034620506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=100) # tuned to 100\n",
    "knn.fit(X_train, Y_train)\n",
    "y_predict_knn = knn.predict(X_test)\n",
    "y_predict_knn = [1 if i > 0.5 else 0 for i in y_predict_knn]\n",
    "print(\"ACC: \", sum([1 if i==j else 0  for i,j in zip(y_predict_knn,Y_test) ])/len(y_predict_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_18 (Dense)            (None, 32)                512       \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " activation_18 (Activation)  (None, 32)                0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 64)                2112      \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " activation_19 (Activation)  (None, 64)                0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 128)               8320      \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " activation_20 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " activation_21 (Activation)  (None, 64)                0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " activation_22 (Activation)  (None, 32)                0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      " activation_23 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,313\n",
      "Trainable params: 21,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#MODELS\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve,\n",
    "]\n",
    "\n",
    "def create_model(idim = ftr_count-1):\n",
    "  model = Sequential()\n",
    "\n",
    "  model.add(Dense(32, input_dim=idim))\n",
    "  model.add(Dropout(.3))\n",
    "  model.add(Activation('gelu'))\n",
    "\n",
    "  model.add(Dense(64, input_dim=32))\n",
    "  model.add(Dropout(.3))\n",
    "  model.add(Activation('gelu'))\n",
    "\n",
    "  model.add(Dense(128, input_dim=64))\n",
    "  model.add(Dropout(.5))\n",
    "  model.add(Activation('gelu'))\n",
    "\n",
    "\n",
    "  model.add(Dense(64, input_dim=128))\n",
    "  model.add(Dropout(.3))\n",
    "  model.add(Activation('gelu'))\n",
    "  \n",
    "  model.add(Dense(32, input_dim=64))\n",
    "  model.add(Dropout(.1))\n",
    "  model.add(Activation('gelu'))\n",
    "\n",
    "  model.add(Dense(1, input_dim=64))\n",
    "  model.add(Activation('sigmoid'))\n",
    "\n",
    "  optimizer = tf.keras.optimizers.SGD(\n",
    "    learning_rate=1e-3, nesterov=False,\n",
    "  )\n",
    "  model.compile(optimizer = optimizer, loss= tfa.losses.SigmoidFocalCrossEntropy(),  metrics=METRICS)\n",
    "  return model\n",
    "\n",
    "\n",
    "# class_weight = compute_class_weight(class_weight = 'balanced', classes = [0,1], y = np.array(df.bot).astype(np.float))\n",
    "# class_weight = {0: class_weight[0],\n",
    "#                 1: class_weight[1]}\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.0828 - tp: 20.0000 - fp: 45.0000 - tn: 910.0000 - fn: 689.0000 - accuracy: 0.5589 - precision: 0.3077 - recall: 0.0282 - auc: 0.5264 - prc: 0.4308\n",
      "Epoch 00001: val_loss improved from inf to 0.07558, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 7s 9ms/step - loss: 0.0825 - tp: 20.0000 - fp: 45.0000 - tn: 961.0000 - fn: 725.0000 - accuracy: 0.5603 - precision: 0.3077 - recall: 0.0268 - auc: 0.5264 - prc: 0.4309 - val_loss: 0.0756 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6328 - val_prc: 0.5819 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.0730 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 958.0000 - fn: 706.0000 - accuracy: 0.5757 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5576 - prc: 0.4588\n",
      "Epoch 00002: val_loss improved from 0.07558 to 0.07159, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0729 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5543 - prc: 0.4580 - val_loss: 0.0716 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6213 - val_prc: 0.5605 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 0.0700 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 949.0000 - fn: 707.0000 - accuracy: 0.5731 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5625 - prc: 0.4642\n",
      "Epoch 00003: val_loss improved from 0.07159 to 0.07044, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0699 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5669 - prc: 0.4658 - val_loss: 0.0704 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6594 - val_prc: 0.6013 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.0692 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1001.0000 - fn: 743.0000 - accuracy: 0.5740 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5509 - prc: 0.4521\n",
      "Epoch 00004: val_loss improved from 0.07044 to 0.07013, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0692 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5509 - prc: 0.4518 - val_loss: 0.0701 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6615 - val_prc: 0.6032 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.0689 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 966.0000 - fn: 714.0000 - accuracy: 0.5750 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5530 - prc: 0.4646\n",
      "Epoch 00005: val_loss improved from 0.07013 to 0.07006, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.0690 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5480 - prc: 0.4614 - val_loss: 0.0701 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6615 - val_prc: 0.6032 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.0689 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 954.0000 - fn: 710.0000 - accuracy: 0.5733 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5608 - prc: 0.4622\n",
      "Epoch 00006: val_loss improved from 0.07006 to 0.07005, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0688 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5639 - prc: 0.4613 - val_loss: 0.0700 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6316 - val_prc: 0.5481 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.0691 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 990.0000 - fn: 738.0000 - accuracy: 0.5729 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5531 - prc: 0.4556\n",
      "Epoch 00007: val_loss did not improve from 0.07005\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.0690 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5529 - prc: 0.4541 - val_loss: 0.0700 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6504 - val_prc: 0.5786 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "209/219 [===========================>..] - ETA: 0s - loss: 0.0686 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 960.0000 - fn: 712.0000 - accuracy: 0.5742 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5765 - prc: 0.4717\n",
      "Epoch 00008: val_loss improved from 0.07005 to 0.07004, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 7ms/step - loss: 0.0686 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5771 - prc: 0.4700 - val_loss: 0.0700 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6543 - val_prc: 0.5981 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.0690 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 990.0000 - fn: 738.0000 - accuracy: 0.5729 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5475 - prc: 0.4426\n",
      "Epoch 00009: val_loss improved from 0.07004 to 0.07003, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.0689 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5479 - prc: 0.4416 - val_loss: 0.0700 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6557 - val_prc: 0.5998 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.0688 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 962.0000 - fn: 718.0000 - accuracy: 0.5726 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5709 - prc: 0.4787\n",
      "Epoch 00010: val_loss improved from 0.07003 to 0.07002, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.0687 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5726 - prc: 0.4788 - val_loss: 0.0700 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6648 - val_prc: 0.6042 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "212/219 [============================>.] - ETA: 0s - loss: 0.0688 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 978.0000 - fn: 718.0000 - accuracy: 0.5767 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5395 - prc: 0.4409\n",
      "Epoch 00011: val_loss improved from 0.07002 to 0.07001, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0690 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5351 - prc: 0.4402 - val_loss: 0.0700 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6574 - val_prc: 0.5968 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "208/219 [===========================>..] - ETA: 0s - loss: 0.0688 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 955.0000 - fn: 709.0000 - accuracy: 0.5739 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5657 - prc: 0.4543\n",
      "Epoch 00012: val_loss improved from 0.07001 to 0.06999, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0687 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5726 - prc: 0.4578 - val_loss: 0.0700 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6548 - val_prc: 0.5973 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "203/219 [==========================>...] - ETA: 0s - loss: 0.0691 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 929.0000 - fn: 695.0000 - accuracy: 0.5720 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5545 - prc: 0.4625\n",
      "Epoch 00013: val_loss improved from 0.06999 to 0.06996, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0689 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5547 - prc: 0.4608 - val_loss: 0.0700 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6640 - val_prc: 0.6044 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.0684 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 975.0000 - fn: 713.0000 - accuracy: 0.5776 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5709 - prc: 0.4535\n",
      "Epoch 00014: val_loss improved from 0.06996 to 0.06993, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0685 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5700 - prc: 0.4557 - val_loss: 0.0699 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6652 - val_prc: 0.6034 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "213/219 [============================>.] - ETA: 0s - loss: 0.0688 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 979.0000 - fn: 725.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5616 - prc: 0.4660\n",
      "Epoch 00015: val_loss improved from 0.06993 to 0.06991, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0688 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5593 - prc: 0.4635 - val_loss: 0.0699 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6637 - val_prc: 0.6024 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "204/219 [==========================>...] - ETA: 0s - loss: 0.0687 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 938.0000 - fn: 694.0000 - accuracy: 0.5748 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5691 - prc: 0.4701\n",
      "Epoch 00016: val_loss improved from 0.06991 to 0.06988, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0686 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5732 - prc: 0.4728 - val_loss: 0.0699 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6552 - val_prc: 0.5794 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.0682 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6087 - prc: 0.5117\n",
      "Epoch 00017: val_loss improved from 0.06988 to 0.06986, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0682 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6087 - prc: 0.5117 - val_loss: 0.0699 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6537 - val_prc: 0.5782 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "213/219 [============================>.] - ETA: 0s - loss: 0.0681 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 984.0000 - fn: 720.0000 - accuracy: 0.5775 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5919 - prc: 0.4887\n",
      "Epoch 00018: val_loss improved from 0.06986 to 0.06984, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 5ms/step - loss: 0.0683 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5891 - prc: 0.4896 - val_loss: 0.0698 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6520 - val_prc: 0.5785 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.0686 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1002.0000 - fn: 742.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5786 - prc: 0.4684\n",
      "Epoch 00019: val_loss improved from 0.06984 to 0.06982, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 6ms/step - loss: 0.0685 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5790 - prc: 0.4687 - val_loss: 0.0698 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6488 - val_prc: 0.5729 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 0.0686 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 955.0000 - fn: 701.0000 - accuracy: 0.5767 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5676 - prc: 0.4623\n",
      "Epoch 00020: val_loss improved from 0.06982 to 0.06980, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0688 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5644 - prc: 0.4627 - val_loss: 0.0698 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6486 - val_prc: 0.5693 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "205/219 [===========================>..] - ETA: 0s - loss: 0.0683 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 940.0000 - fn: 700.0000 - accuracy: 0.5732 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5878 - prc: 0.4762\n",
      "Epoch 00021: val_loss improved from 0.06980 to 0.06977, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0683 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5911 - prc: 0.4775 - val_loss: 0.0698 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6495 - val_prc: 0.5686 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "204/219 [==========================>...] - ETA: 0s - loss: 0.0684 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 941.0000 - fn: 691.0000 - accuracy: 0.5766 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5793 - prc: 0.4694\n",
      "Epoch 00022: val_loss improved from 0.06977 to 0.06974, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0686 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5775 - prc: 0.4681 - val_loss: 0.0697 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6594 - val_prc: 0.5953 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.0686 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 984.0000 - fn: 728.0000 - accuracy: 0.5748 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5753 - prc: 0.4763\n",
      "Epoch 00023: val_loss improved from 0.06974 to 0.06971, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0685 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5779 - prc: 0.4791 - val_loss: 0.0697 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6546 - val_prc: 0.5900 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.0682 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5962 - prc: 0.4805\n",
      "Epoch 00024: val_loss improved from 0.06971 to 0.06969, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0682 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5962 - prc: 0.4805 - val_loss: 0.0697 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6545 - val_prc: 0.5933 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "205/219 [===========================>..] - ETA: 0s - loss: 0.0688 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 939.0000 - fn: 701.0000 - accuracy: 0.5726 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5748 - prc: 0.4896\n",
      "Epoch 00025: val_loss improved from 0.06969 to 0.06966, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0686 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5769 - prc: 0.4868 - val_loss: 0.0697 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6593 - val_prc: 0.5980 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "206/219 [===========================>..] - ETA: 0s - loss: 0.0684 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 947.0000 - fn: 701.0000 - accuracy: 0.5746 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5895 - prc: 0.4944\n",
      "Epoch 00026: val_loss improved from 0.06966 to 0.06964, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0684 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5913 - prc: 0.4956 - val_loss: 0.0696 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6596 - val_prc: 0.5981 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.0682 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 959.0000 - fn: 721.0000 - accuracy: 0.5708 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6069 - prc: 0.5029\n",
      "Epoch 00027: val_loss improved from 0.06964 to 0.06962, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0680 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6070 - prc: 0.4980 - val_loss: 0.0696 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6577 - val_prc: 0.5975 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "204/219 [==========================>...] - ETA: 0s - loss: 0.0684 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 939.0000 - fn: 693.0000 - accuracy: 0.5754 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5790 - prc: 0.4793\n",
      "Epoch 00028: val_loss improved from 0.06962 to 0.06960, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0686 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5721 - prc: 0.4740 - val_loss: 0.0696 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6601 - val_prc: 0.5980 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "213/219 [============================>.] - ETA: 0s - loss: 0.0685 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 979.0000 - fn: 725.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6003 - prc: 0.4995\n",
      "Epoch 00029: val_loss improved from 0.06960 to 0.06958, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0685 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5974 - prc: 0.4974 - val_loss: 0.0696 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6602 - val_prc: 0.5992 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "202/219 [==========================>...] - ETA: 0s - loss: 0.0685 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 924.0000 - fn: 692.0000 - accuracy: 0.5718 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5858 - prc: 0.4842\n",
      "Epoch 00030: val_loss improved from 0.06958 to 0.06955, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0682 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5896 - prc: 0.4835 - val_loss: 0.0696 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6603 - val_prc: 0.5995 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "205/219 [===========================>..] - ETA: 0s - loss: 0.0678 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 950.0000 - fn: 690.0000 - accuracy: 0.5793 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6103 - prc: 0.5050\n",
      "Epoch 00031: val_loss improved from 0.06955 to 0.06953, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0680 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6090 - prc: 0.5074 - val_loss: 0.0695 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6612 - val_prc: 0.5999 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "204/219 [==========================>...] - ETA: 0s - loss: 0.0683 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 942.0000 - fn: 690.0000 - accuracy: 0.5772 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5874 - prc: 0.4942\n",
      "Epoch 00032: val_loss improved from 0.06953 to 0.06951, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0684 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5940 - prc: 0.5049 - val_loss: 0.0695 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6586 - val_prc: 0.5882 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.0684 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 999.0000 - fn: 745.0000 - accuracy: 0.5728 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5914 - prc: 0.4954\n",
      "Epoch 00033: val_loss improved from 0.06951 to 0.06948, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0683 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5914 - prc: 0.4939 - val_loss: 0.0695 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6526 - val_prc: 0.5759 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 0.0682 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 955.0000 - fn: 701.0000 - accuracy: 0.5767 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5894 - prc: 0.4898\n",
      "Epoch 00034: val_loss improved from 0.06948 to 0.06946, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0683 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5900 - prc: 0.4909 - val_loss: 0.0695 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6514 - val_prc: 0.5784 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "203/219 [==========================>...] - ETA: 0s - loss: 0.0680 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 938.0000 - fn: 686.0000 - accuracy: 0.5776 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6006 - prc: 0.4921\n",
      "Epoch 00035: val_loss improved from 0.06946 to 0.06944, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0681 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6036 - prc: 0.4982 - val_loss: 0.0694 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6529 - val_prc: 0.5846 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.0681 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 963.0000 - fn: 717.0000 - accuracy: 0.5732 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6070 - prc: 0.5062\n",
      "Epoch 00036: val_loss improved from 0.06944 to 0.06942, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0681 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6059 - prc: 0.5056 - val_loss: 0.0694 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6587 - val_prc: 0.6028 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.0681 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 967.0000 - fn: 713.0000 - accuracy: 0.5756 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5956 - prc: 0.4968\n",
      "Epoch 00037: val_loss improved from 0.06942 to 0.06939, saving model to ./ckpts/best_val_loss.hdf5\n",
      "\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0681 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5992 - prc: 0.5010 - val_loss: 0.0694 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6568 - val_prc: 0.5952 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.0682 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 991.0000 - fn: 737.0000 - accuracy: 0.5735 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5956 - prc: 0.5052\n",
      "Epoch 00038: val_loss improved from 0.06939 to 0.06939, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0681 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5954 - prc: 0.5030 - val_loss: 0.0694 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6568 - val_prc: 0.5952 - lr: 1.0000e-04\n",
      "Epoch 39/50\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 0.0683 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 946.0000 - fn: 710.0000 - accuracy: 0.5713 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5973 - prc: 0.5000\n",
      "Epoch 00039: val_loss improved from 0.06939 to 0.06938, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0680 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6024 - prc: 0.4990 - val_loss: 0.0694 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6568 - val_prc: 0.5952 - lr: 1.0000e-04\n",
      "Epoch 40/50\n",
      "206/219 [===========================>..] - ETA: 0s - loss: 0.0687 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 944.0000 - fn: 704.0000 - accuracy: 0.5728 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5839 - prc: 0.4836\n",
      "Epoch 00040: val_loss improved from 0.06938 to 0.06938, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0686 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5811 - prc: 0.4788 - val_loss: 0.0694 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6568 - val_prc: 0.5952 - lr: 1.0000e-04\n",
      "Epoch 41/50\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.0680 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 992.0000 - fn: 736.0000 - accuracy: 0.5741 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6124 - prc: 0.5101\n",
      "Epoch 00041: val_loss improved from 0.06938 to 0.06938, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0680 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6104 - prc: 0.5072 - val_loss: 0.0694 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6566 - val_prc: 0.5950 - lr: 1.0000e-04\n",
      "Epoch 42/50\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.0683 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 983.0000 - fn: 729.0000 - accuracy: 0.5742 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5945 - prc: 0.4890\n",
      "Epoch 00042: val_loss improved from 0.06938 to 0.06938, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0682 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5952 - prc: 0.4888 - val_loss: 0.0694 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6577 - val_prc: 0.5967 - lr: 1.0000e-04\n",
      "Epoch 43/50\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.0685 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 991.0000 - fn: 737.0000 - accuracy: 0.5735 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5874 - prc: 0.4847\n",
      "Epoch 00043: val_loss improved from 0.06938 to 0.06938, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0685 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5870 - prc: 0.4827 - val_loss: 0.0694 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6577 - val_prc: 0.5967 - lr: 1.0000e-04\n",
      "Epoch 44/50\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 0.0681 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 949.0000 - fn: 707.0000 - accuracy: 0.5731 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6034 - prc: 0.4956\n",
      "Epoch 00044: val_loss improved from 0.06938 to 0.06938, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0680 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6066 - prc: 0.4952 - val_loss: 0.0694 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6573 - val_prc: 0.5965 - lr: 1.0000e-04\n",
      "Epoch 45/50\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.0681 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 971.0000 - fn: 717.0000 - accuracy: 0.5752 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5917 - prc: 0.4921\n",
      "Epoch 00045: val_loss improved from 0.06938 to 0.06937, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0682 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5911 - prc: 0.4931 - val_loss: 0.0694 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6572 - val_prc: 0.5965 - lr: 1.0000e-04\n",
      "Epoch 46/50\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 0.0679 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 948.0000 - fn: 708.0000 - accuracy: 0.5725 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6106 - prc: 0.5046\n",
      "Epoch 00046: val_loss improved from 0.06937 to 0.06937, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0677 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6120 - prc: 0.5016 - val_loss: 0.0694 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6572 - val_prc: 0.5965 - lr: 1.0000e-04\n",
      "Epoch 47/50\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.0684 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 996.0000 - fn: 740.0000 - accuracy: 0.5737 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5907 - prc: 0.4810\n",
      "Epoch 00047: val_loss improved from 0.06937 to 0.06937, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0684 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5908 - prc: 0.4787 - val_loss: 0.0694 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6572 - val_prc: 0.5965 - lr: 1.0000e-04\n",
      "Epoch 48/50\n",
      "212/219 [============================>.] - ETA: 0s - loss: 0.0680 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 975.0000 - fn: 721.0000 - accuracy: 0.5749 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6097 - prc: 0.5071\n",
      "Epoch 00048: val_loss improved from 0.06937 to 0.06937, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0680 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6114 - prc: 0.5085 - val_loss: 0.0694 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6572 - val_prc: 0.5965 - lr: 1.0000e-04\n",
      "Epoch 49/50\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.0681 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5988 - prc: 0.4906\n",
      "Epoch 00049: val_loss improved from 0.06937 to 0.06937, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0681 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5988 - prc: 0.4906 - val_loss: 0.0694 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6572 - val_prc: 0.5965 - lr: 1.0000e-04\n",
      "Epoch 50/50\n",
      "205/219 [===========================>..] - ETA: 0s - loss: 0.0677 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 937.0000 - fn: 703.0000 - accuracy: 0.5713 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6299 - prc: 0.5294\n",
      "Epoch 00050: val_loss improved from 0.06937 to 0.06936, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 1s 4ms/step - loss: 0.0676 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6280 - prc: 0.5214 - val_loss: 0.0694 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6572 - val_prc: 0.5965 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(x=X_train.astype(np.float), y=Y_train.astype(np.float), batch_size=8, epochs=50, validation_data=(X_test.astype(np.float), Y_test.astype(np.float)), verbose=1, shuffle=True, callbacks=\n",
    "                                [ModelCheckpoint(filepath='./ckpts/best_val_loss.hdf5',\n",
    "                                               monitor= 'val_loss',\n",
    "                                               save_best_only=True,\n",
    "                                               mode='auto',\n",
    "                                               save_weights_only=True,\n",
    "                                               verbose=2),\n",
    "                                EarlyStopping(monitor='val_loss',\n",
    "                                             mode='auto',\n",
    "                                             patience=100,\n",
    "                                             verbose=1),  \n",
    "                                ReduceLROnPlateau(\n",
    "                                monitor='loss', factor=0.1, patience=10, verbose=1,\n",
    "                                mode='auto', min_delta=0.0001, cooldown=0, min_lr=0\n",
    "                            )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[407, 344],\n",
       "       [  0,   0]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['loss']\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='val')\n",
    "pyplot.xlabel(\"Epochs\")\n",
    "pyplot.ylabel(\"Loss\")\n",
    "pyplot.title(\"Training and Validation Loss Over %d Epochs\" % (len(history.history['loss']),))\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "\n",
    "history.history['accuracy']\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='val')\n",
    "pyplot.xlabel(\"Epochs\")\n",
    "pyplot.ylabel(\"Accuracy\")\n",
    "pyplot.title(\"Training and Validation Accuracy Over %d Epochs\" % (len(history.history['loss']),))\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    " \n",
    "from sklearn.metrics import log_loss # The data is binary\n",
    "from math import sqrt\n",
    "\n",
    "model.built = True\n",
    "model.load_weights(\"ckpts/best_val_loss.hdf5\")\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = [1 if i > 0.5 else 0 for i in y_pred] # roc curve when you change threshold\n",
    "confusion_matrix(y_pred, Y_test)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cc4240bb6330fdaa0e5b1d4f2184411e5109cd7a3e886f36b28dcc715df5a2e5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('stonks': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
