{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import f\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from matplotlib import pyplot\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "import keras\n",
    "import texthero as hero\n",
    "from texthero import preprocessing as str_preprocessing\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_and_bind(original_dataframe, feature_to_encode): # utility function for one-hot encoding\n",
    "    dummies = pd.get_dummies(original_dataframe[[feature_to_encode]])\n",
    "    res = pd.concat([original_dataframe, dummies], axis=1)\n",
    "    return(res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>geo_enabled</th>\n",
       "      <th>verified</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>contributors_enabled</th>\n",
       "      <th>profile_use_background_image</th>\n",
       "      <th>has_extended_profile</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>default_profile_image</th>\n",
       "      <th>following</th>\n",
       "      <th>follow_request_sent</th>\n",
       "      <th>notifications</th>\n",
       "      <th>bot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BaseballQuotes1</td>\n",
       "      <td>The Diamond</td>\n",
       "      <td>Quoting America's Pastime in 280 characters or...</td>\n",
       "      <td>121500</td>\n",
       "      <td>346</td>\n",
       "      <td>532</td>\n",
       "      <td>35894</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>21246</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cavs</td>\n",
       "      <td>The Q | Cleveland, OH</td>\n",
       "      <td>Official Twitter of the 2016 NBA Champion Clev...</td>\n",
       "      <td>3227215</td>\n",
       "      <td>1946</td>\n",
       "      <td>9039</td>\n",
       "      <td>16134</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>45791</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>muohajer_12</td>\n",
       "      <td>ÿßŸÑŸÖŸÖŸÑŸÉÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ÿßŸÑÿ≥ÿπŸàÿØŸäÿ©</td>\n",
       "      <td></td>\n",
       "      <td>864968</td>\n",
       "      <td>767106</td>\n",
       "      <td>1371</td>\n",
       "      <td>23</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>875763</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bc20_</td>\n",
       "      <td></td>\n",
       "      <td>R.I.P JRL21//R.I.P Monicaüíô IG//b.20c #GLOHIOBOYS</td>\n",
       "      <td>951</td>\n",
       "      <td>275</td>\n",
       "      <td>9</td>\n",
       "      <td>22147</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>88862</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_Blkahontas</td>\n",
       "      <td>Hollywood, FL</td>\n",
       "      <td>to die for üîÆü§ûüèæüë∏üèæ</td>\n",
       "      <td>1412</td>\n",
       "      <td>623</td>\n",
       "      <td>12</td>\n",
       "      <td>5582</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>142073</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>BigMacFlashy</td>\n",
       "      <td>Phoenix, AZ</td>\n",
       "      <td>CEO of @thebambox and @comiconauction. Love De...</td>\n",
       "      <td>331</td>\n",
       "      <td>154</td>\n",
       "      <td>1</td>\n",
       "      <td>350</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>325</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>BadruulAminn</td>\n",
       "      <td>Petaling, Selangor</td>\n",
       "      <td>20 / YouTuber + Streamer / Married /\\n\\nCome s...</td>\n",
       "      <td>71105</td>\n",
       "      <td>62028</td>\n",
       "      <td>27</td>\n",
       "      <td>1818</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>27006</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>anxietyhes</td>\n",
       "      <td></td>\n",
       "      <td>woke up the girl who looked just like you I al...</td>\n",
       "      <td>99769</td>\n",
       "      <td>67170</td>\n",
       "      <td>335</td>\n",
       "      <td>27192</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>81781</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>EN_owl</td>\n",
       "      <td>„Å™„Åî„ÇÑ„Å°„Åª„Éº</td>\n",
       "      <td>ÊóßÂûã„ÇØ„É≠„Çπ„Ç´„ÉñÊîπ(„Éó„É©„Ç¶„ÉÄÊà¶ËªäËâ≤)„Å´‰πó„Çã„Ç¨„É´„Éë„É≥„Åä„Åò„Åï„Çì„ÄÇ„Éé„É≥„Éä„Å®ÊÑõÈáåÂØøÊé®„Åó„ÄÇÊó•Êú¨‰∏ÄÂë®201...</td>\n",
       "      <td>1222</td>\n",
       "      <td>244</td>\n",
       "      <td>102</td>\n",
       "      <td>382</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>70120</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>cessdomingo_</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1308</td>\n",
       "      <td>1017</td>\n",
       "      <td>0</td>\n",
       "      <td>39669</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>44078</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2502 rows √ó 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          screen_name                  location  \\\n",
       "0     BaseballQuotes1               The Diamond   \n",
       "1                cavs     The Q | Cleveland, OH   \n",
       "2         muohajer_12  ÿßŸÑŸÖŸÖŸÑŸÉÿ© ÿßŸÑÿπÿ±ÿ®Ÿäÿ© ÿßŸÑÿ≥ÿπŸàÿØŸäÿ©   \n",
       "3               Bc20_                             \n",
       "4         _Blkahontas             Hollywood, FL   \n",
       "...               ...                       ...   \n",
       "2497     BigMacFlashy               Phoenix, AZ   \n",
       "2498     BadruulAminn        Petaling, Selangor   \n",
       "2499       anxietyhes                             \n",
       "2500           EN_owl                    „Å™„Åî„ÇÑ„Å°„Åª„Éº   \n",
       "2501     cessdomingo_                             \n",
       "\n",
       "                                            description  followers_count  \\\n",
       "0     Quoting America's Pastime in 280 characters or...           121500   \n",
       "1     Official Twitter of the 2016 NBA Champion Clev...          3227215   \n",
       "2                                                                 864968   \n",
       "3      R.I.P JRL21//R.I.P Monicaüíô IG//b.20c #GLOHIOBOYS              951   \n",
       "4                                      to die for üîÆü§ûüèæüë∏üèæ             1412   \n",
       "...                                                 ...              ...   \n",
       "2497  CEO of @thebambox and @comiconauction. Love De...              331   \n",
       "2498  20 / YouTuber + Streamer / Married /\\n\\nCome s...            71105   \n",
       "2499  woke up the girl who looked just like you I al...            99769   \n",
       "2500  ÊóßÂûã„ÇØ„É≠„Çπ„Ç´„ÉñÊîπ(„Éó„É©„Ç¶„ÉÄÊà¶ËªäËâ≤)„Å´‰πó„Çã„Ç¨„É´„Éë„É≥„Åä„Åò„Åï„Çì„ÄÇ„Éé„É≥„Éä„Å®ÊÑõÈáåÂØøÊé®„Åó„ÄÇÊó•Êú¨‰∏ÄÂë®201...             1222   \n",
       "2501                                                                1308   \n",
       "\n",
       "      friends_count  listed_count  favourites_count  geo_enabled  verified  \\\n",
       "0               346           532             35894         True     False   \n",
       "1              1946          9039             16134         True      True   \n",
       "2            767106          1371                23         True     False   \n",
       "3               275             9             22147         True     False   \n",
       "4               623            12              5582         True     False   \n",
       "...             ...           ...               ...          ...       ...   \n",
       "2497            154             1               350        False     False   \n",
       "2498          62028            27              1818        False     False   \n",
       "2499          67170           335             27192         True     False   \n",
       "2500            244           102               382        False     False   \n",
       "2501           1017             0             39669         True     False   \n",
       "\n",
       "      statuses_count  contributors_enabled  profile_use_background_image  \\\n",
       "0              21246                 False                         False   \n",
       "1              45791                 False                          True   \n",
       "2             875763                 False                          True   \n",
       "3              88862                 False                         False   \n",
       "4             142073                 False                          True   \n",
       "...              ...                   ...                           ...   \n",
       "2497             325                 False                         False   \n",
       "2498           27006                 False                          True   \n",
       "2499           81781                 False                          True   \n",
       "2500           70120                 False                          True   \n",
       "2501           44078                 False                          True   \n",
       "\n",
       "      has_extended_profile  default_profile  default_profile_image  following  \\\n",
       "0                    False            False                  False      False   \n",
       "1                    False            False                  False      False   \n",
       "2                    False             True                  False      False   \n",
       "3                     True            False                  False      False   \n",
       "4                    False            False                  False      False   \n",
       "...                    ...              ...                    ...        ...   \n",
       "2497                 False            False                  False      False   \n",
       "2498                  True            False                  False      False   \n",
       "2499                  True            False                  False      False   \n",
       "2500                 False            False                  False      False   \n",
       "2501                 False            False                  False      False   \n",
       "\n",
       "      follow_request_sent  notifications  bot  \n",
       "0                   False          False    0  \n",
       "1                   False          False    0  \n",
       "2                   False          False    1  \n",
       "3                   False          False    0  \n",
       "4                   False          False    0  \n",
       "...                   ...            ...  ...  \n",
       "2497                False          False    0  \n",
       "2498                False          False    0  \n",
       "2499                False          False    0  \n",
       "2500                False          False    1  \n",
       "2501                False          False    0  \n",
       "\n",
       "[2502 rows x 19 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv (\"./gilani-2017/gilani-2017.tsv\", sep = '\\t')\n",
    "labels['id'] = labels['461277906']\n",
    "df = pd.read_json(\"./gilani-2017/gilani-2017_tweets.json\")\n",
    "df = pd.json_normalize(df['user'])\n",
    "df.columns = df.columns.map(lambda x: x.split(\".\")[-1])\n",
    "df = pd.merge(df,labels,on='id')\n",
    "\n",
    "df = df.drop(['461277906', 'lang', 'is_translator', 'is_translation_enabled',  'profile_background_tile',  'profile_background_color', 'profile_background_image_url', 'time_zone', 'profile_background_image_url_https', 'id', 'created_at', 'profile_image_url', 'profile_image_url_https', 'utc_offset' , 'url', 'profile_banner_url','protected','name','translator_type', 'urls', 'id_str', 'profile_sidebar_border_color', 'profile_sidebar_fill_color', 'profile_text_color', 'profile_link_color'], axis = 1)\n",
    "df.bot = [1 if i == 'bot' else 0 for i in df.bot]\n",
    "df = df.dropna(axis = 1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.asarray(df.drop(['bot'], axis = 1))\n",
    "\n",
    "\n",
    "custom_pipeline = [str_preprocessing.fillna,\n",
    "                   str_preprocessing.remove_whitespace,\n",
    "                   str_preprocessing.remove_diacritics,\n",
    "                   str_preprocessing.remove_brackets\n",
    "                  ]\n",
    "\n",
    "string_cols = ['screen_name', 'location', 'description' ]\n",
    "for ftr in string_cols:\n",
    "    df[ftr] = hero.clean(df[ftr], custom_pipeline)\n",
    "\n",
    "ftrs = ['followers_count', 'friends_count', 'listed_count', 'favourites_count', 'statuses_count']\n",
    "for ftr in ftrs:\n",
    "    df[ftr] = (np.array(df[ftr]) - np.mean(df[ftr]))/max(df[ftr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screen_name</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>friends_count</th>\n",
       "      <th>listed_count</th>\n",
       "      <th>favourites_count</th>\n",
       "      <th>geo_enabled</th>\n",
       "      <th>verified</th>\n",
       "      <th>statuses_count</th>\n",
       "      <th>contributors_enabled</th>\n",
       "      <th>profile_use_background_image</th>\n",
       "      <th>has_extended_profile</th>\n",
       "      <th>default_profile</th>\n",
       "      <th>default_profile_image</th>\n",
       "      <th>following</th>\n",
       "      <th>follow_request_sent</th>\n",
       "      <th>notifications</th>\n",
       "      <th>bot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.0029235822, 0.0009731989, 0.003845133, 0.0...</td>\n",
       "      <td>[0.07173307, -0.01923275, -0.16587935, -0.0473...</td>\n",
       "      <td>[0.010236139, 0.13572639, -0.15832372, 0.05888...</td>\n",
       "      <td>-0.009569</td>\n",
       "      <td>-0.009499</td>\n",
       "      <td>-0.003988</td>\n",
       "      <td>0.024466</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.022961</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.0011937198, -0.0024638425, -0.0009366568, ...</td>\n",
       "      <td>[0.12813754, -0.0302265, -0.27940464, -0.09270...</td>\n",
       "      <td>[0.046057392, 0.32741794, -0.47158957, 0.08985...</td>\n",
       "      <td>0.019473</td>\n",
       "      <td>-0.008751</td>\n",
       "      <td>0.010039</td>\n",
       "      <td>0.002166</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>-0.014089</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.003372603, 0.0031725352, 0.006777673, 0.000...</td>\n",
       "      <td>[0.015201126, 0.007930698, -0.025799846, -0.00...</td>\n",
       "      <td>[0.071908236, 0.006891489, -0.054388717, -0.01...</td>\n",
       "      <td>-0.002617</td>\n",
       "      <td>0.348570</td>\n",
       "      <td>-0.002604</td>\n",
       "      <td>-0.016015</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.285917</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.0051671015, 0.002487781, -0.006696592, 0.0...</td>\n",
       "      <td>[0.000762711, 0.0033623339, 0.0016056778, 0.00...</td>\n",
       "      <td>[0.12924662, 0.24893342, -0.35582605, 0.090235...</td>\n",
       "      <td>-0.010696</td>\n",
       "      <td>-0.009532</td>\n",
       "      <td>-0.004850</td>\n",
       "      <td>0.008952</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001480</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.00078907644, 0.005356739, 0.00093507936, -...</td>\n",
       "      <td>[0.058649532, -0.012225129, -0.11253808, -0.03...</td>\n",
       "      <td>[-0.13005425, -0.03909892, 0.06288386, -0.0219...</td>\n",
       "      <td>-0.010692</td>\n",
       "      <td>-0.009369</td>\n",
       "      <td>-0.004845</td>\n",
       "      <td>-0.009742</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>0.020714</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2497</th>\n",
       "      <td>[-0.0007070329, 0.0010249995, -0.006834164, 0....</td>\n",
       "      <td>[0.10129081, -0.0260801, -0.20394132, -0.06667...</td>\n",
       "      <td>[-0.015109202, 0.3204942, -0.40000945, 0.11030...</td>\n",
       "      <td>-0.010702</td>\n",
       "      <td>-0.009588</td>\n",
       "      <td>-0.004863</td>\n",
       "      <td>-0.015646</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.030523</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2498</th>\n",
       "      <td>[-0.0058407215, 0.0043555056, -0.0057156184, 0...</td>\n",
       "      <td>[0.12696862, -0.019098967, -0.25703022, -0.089...</td>\n",
       "      <td>[-0.18777004, 0.12944484, -0.34768906, -0.1080...</td>\n",
       "      <td>-0.010040</td>\n",
       "      <td>0.019306</td>\n",
       "      <td>-0.004820</td>\n",
       "      <td>-0.013990</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.020879</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2499</th>\n",
       "      <td>[0.0053639486, -0.0017949232, 0.0025525168, 0....</td>\n",
       "      <td>[-0.01638254, 0.007129405, 0.038211696, 0.0126...</td>\n",
       "      <td>[-0.17191581, 0.26394582, -0.16108549, 0.09044...</td>\n",
       "      <td>-0.009772</td>\n",
       "      <td>0.021707</td>\n",
       "      <td>-0.004312</td>\n",
       "      <td>0.014646</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.001080</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500</th>\n",
       "      <td>[-0.005395382, -0.0043554995, -0.0029624724, -...</td>\n",
       "      <td>[0.055919465, -0.009552755, -0.13517085, -0.04...</td>\n",
       "      <td>[1.0962037, 0.8957365, -1.4802097, -0.13300388...</td>\n",
       "      <td>-0.010694</td>\n",
       "      <td>-0.009546</td>\n",
       "      <td>-0.004697</td>\n",
       "      <td>-0.015610</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.005295</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2501</th>\n",
       "      <td>[0.0011933864, -0.0019287707, -0.0060814233, 0...</td>\n",
       "      <td>[-0.012168328, 0.0062313094, 0.028959068, 0.00...</td>\n",
       "      <td>[0.06688238, 0.007105454, -0.045076557, -0.008...</td>\n",
       "      <td>-0.010693</td>\n",
       "      <td>-0.009185</td>\n",
       "      <td>-0.004865</td>\n",
       "      <td>0.028726</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.014708</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2502 rows √ó 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            screen_name  \\\n",
       "0     [-0.0029235822, 0.0009731989, 0.003845133, 0.0...   \n",
       "1     [-0.0011937198, -0.0024638425, -0.0009366568, ...   \n",
       "2     [0.003372603, 0.0031725352, 0.006777673, 0.000...   \n",
       "3     [-0.0051671015, 0.002487781, -0.006696592, 0.0...   \n",
       "4     [-0.00078907644, 0.005356739, 0.00093507936, -...   \n",
       "...                                                 ...   \n",
       "2497  [-0.0007070329, 0.0010249995, -0.006834164, 0....   \n",
       "2498  [-0.0058407215, 0.0043555056, -0.0057156184, 0...   \n",
       "2499  [0.0053639486, -0.0017949232, 0.0025525168, 0....   \n",
       "2500  [-0.005395382, -0.0043554995, -0.0029624724, -...   \n",
       "2501  [0.0011933864, -0.0019287707, -0.0060814233, 0...   \n",
       "\n",
       "                                               location  \\\n",
       "0     [0.07173307, -0.01923275, -0.16587935, -0.0473...   \n",
       "1     [0.12813754, -0.0302265, -0.27940464, -0.09270...   \n",
       "2     [0.015201126, 0.007930698, -0.025799846, -0.00...   \n",
       "3     [0.000762711, 0.0033623339, 0.0016056778, 0.00...   \n",
       "4     [0.058649532, -0.012225129, -0.11253808, -0.03...   \n",
       "...                                                 ...   \n",
       "2497  [0.10129081, -0.0260801, -0.20394132, -0.06667...   \n",
       "2498  [0.12696862, -0.019098967, -0.25703022, -0.089...   \n",
       "2499  [-0.01638254, 0.007129405, 0.038211696, 0.0126...   \n",
       "2500  [0.055919465, -0.009552755, -0.13517085, -0.04...   \n",
       "2501  [-0.012168328, 0.0062313094, 0.028959068, 0.00...   \n",
       "\n",
       "                                            description  followers_count  \\\n",
       "0     [0.010236139, 0.13572639, -0.15832372, 0.05888...        -0.009569   \n",
       "1     [0.046057392, 0.32741794, -0.47158957, 0.08985...         0.019473   \n",
       "2     [0.071908236, 0.006891489, -0.054388717, -0.01...        -0.002617   \n",
       "3     [0.12924662, 0.24893342, -0.35582605, 0.090235...        -0.010696   \n",
       "4     [-0.13005425, -0.03909892, 0.06288386, -0.0219...        -0.010692   \n",
       "...                                                 ...              ...   \n",
       "2497  [-0.015109202, 0.3204942, -0.40000945, 0.11030...        -0.010702   \n",
       "2498  [-0.18777004, 0.12944484, -0.34768906, -0.1080...        -0.010040   \n",
       "2499  [-0.17191581, 0.26394582, -0.16108549, 0.09044...        -0.009772   \n",
       "2500  [1.0962037, 0.8957365, -1.4802097, -0.13300388...        -0.010694   \n",
       "2501  [0.06688238, 0.007105454, -0.045076557, -0.008...        -0.010693   \n",
       "\n",
       "      friends_count  listed_count  favourites_count  geo_enabled  verified  \\\n",
       "0         -0.009499     -0.003988          0.024466         True     False   \n",
       "1         -0.008751      0.010039          0.002166         True      True   \n",
       "2          0.348570     -0.002604         -0.016015         True     False   \n",
       "3         -0.009532     -0.004850          0.008952         True     False   \n",
       "4         -0.009369     -0.004845         -0.009742         True     False   \n",
       "...             ...           ...               ...          ...       ...   \n",
       "2497      -0.009588     -0.004863         -0.015646        False     False   \n",
       "2498       0.019306     -0.004820         -0.013990        False     False   \n",
       "2499       0.021707     -0.004312          0.014646         True     False   \n",
       "2500      -0.009546     -0.004697         -0.015610        False     False   \n",
       "2501      -0.009185     -0.004865          0.028726         True     False   \n",
       "\n",
       "      statuses_count  contributors_enabled  profile_use_background_image  \\\n",
       "0          -0.022961                 False                         False   \n",
       "1          -0.014089                 False                          True   \n",
       "2           0.285917                 False                          True   \n",
       "3           0.001480                 False                         False   \n",
       "4           0.020714                 False                          True   \n",
       "...              ...                   ...                           ...   \n",
       "2497       -0.030523                 False                         False   \n",
       "2498       -0.020879                 False                          True   \n",
       "2499       -0.001080                 False                          True   \n",
       "2500       -0.005295                 False                          True   \n",
       "2501       -0.014708                 False                          True   \n",
       "\n",
       "      has_extended_profile  default_profile  default_profile_image  following  \\\n",
       "0                    False            False                  False      False   \n",
       "1                    False            False                  False      False   \n",
       "2                    False             True                  False      False   \n",
       "3                     True            False                  False      False   \n",
       "4                    False            False                  False      False   \n",
       "...                    ...              ...                    ...        ...   \n",
       "2497                 False            False                  False      False   \n",
       "2498                  True            False                  False      False   \n",
       "2499                  True            False                  False      False   \n",
       "2500                 False            False                  False      False   \n",
       "2501                 False            False                  False      False   \n",
       "\n",
       "      follow_request_sent  notifications  bot  \n",
       "0                   False          False    0  \n",
       "1                   False          False    0  \n",
       "2                   False          False    1  \n",
       "3                   False          False    0  \n",
       "4                   False          False    0  \n",
       "...                   ...            ...  ...  \n",
       "2497                False          False    0  \n",
       "2498                False          False    0  \n",
       "2499                False          False    0  \n",
       "2500                False          False    1  \n",
       "2501                False          False    0  \n",
       "\n",
       "[2502 rows x 19 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for ftr in string_cols: #vector encoding\n",
    "    tokens = [TaggedDocument(doc.split(' '), [i]) \n",
    "                for i, doc in enumerate(df[ftr])]\n",
    "    model = Doc2Vec(vector_size=64, window=2, min_count=1, workers=8, epochs = 40)\n",
    "    model.build_vocab(tokens)\n",
    "    model.train(tokens, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "    card2vec = [model.infer_vector((df[ftr][i].split(' '))) \n",
    "            for i in range(0,len(df[ftr]))]\n",
    "    df[ftr] = card2vec\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      followers_count  friends_count  listed_count  favourites_count  \\\n",
      "0           -0.009569      -0.009499     -0.003988          0.024466   \n",
      "1            0.019473      -0.008751      0.010039          0.002166   \n",
      "2           -0.002617       0.348570     -0.002604         -0.016015   \n",
      "3           -0.010696      -0.009532     -0.004850          0.008952   \n",
      "4           -0.010692      -0.009369     -0.004845         -0.009742   \n",
      "...               ...            ...           ...               ...   \n",
      "2497        -0.010702      -0.009588     -0.004863         -0.015646   \n",
      "2498        -0.010040       0.019306     -0.004820         -0.013990   \n",
      "2499        -0.009772       0.021707     -0.004312          0.014646   \n",
      "2500        -0.010694      -0.009546     -0.004697         -0.015610   \n",
      "2501        -0.010693      -0.009185     -0.004865          0.028726   \n",
      "\n",
      "      geo_enabled  verified  statuses_count  contributors_enabled  \\\n",
      "0            True     False       -0.022961                 False   \n",
      "1            True      True       -0.014089                 False   \n",
      "2            True     False        0.285917                 False   \n",
      "3            True     False        0.001480                 False   \n",
      "4            True     False        0.020714                 False   \n",
      "...           ...       ...             ...                   ...   \n",
      "2497        False     False       -0.030523                 False   \n",
      "2498        False     False       -0.020879                 False   \n",
      "2499         True     False       -0.001080                 False   \n",
      "2500        False     False       -0.005295                 False   \n",
      "2501         True     False       -0.014708                 False   \n",
      "\n",
      "      profile_use_background_image  has_extended_profile  default_profile  \\\n",
      "0                            False                 False            False   \n",
      "1                             True                 False            False   \n",
      "2                             True                 False             True   \n",
      "3                            False                  True            False   \n",
      "4                             True                 False            False   \n",
      "...                            ...                   ...              ...   \n",
      "2497                         False                 False            False   \n",
      "2498                          True                  True            False   \n",
      "2499                          True                  True            False   \n",
      "2500                          True                 False            False   \n",
      "2501                          True                 False            False   \n",
      "\n",
      "      default_profile_image  following  follow_request_sent  notifications  \\\n",
      "0                     False      False                False          False   \n",
      "1                     False      False                False          False   \n",
      "2                     False      False                False          False   \n",
      "3                     False      False                False          False   \n",
      "4                     False      False                False          False   \n",
      "...                     ...        ...                  ...            ...   \n",
      "2497                  False      False                False          False   \n",
      "2498                  False      False                False          False   \n",
      "2499                  False      False                False          False   \n",
      "2500                  False      False                False          False   \n",
      "2501                  False      False                False          False   \n",
      "\n",
      "      bot  \n",
      "0       0  \n",
      "1       0  \n",
      "2       1  \n",
      "3       0  \n",
      "4       0  \n",
      "...   ...  \n",
      "2497    0  \n",
      "2498    0  \n",
      "2499    0  \n",
      "2500    1  \n",
      "2501    0  \n",
      "\n",
      "[2502 rows x 16 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-f546824912c3>:13: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  X_train, X_test, Y_train, Y_test = X_train.astype(np.float), X_test.astype(np.float), Y_train.astype(np.float), Y_test.astype(np.float)\n"
     ]
    }
   ],
   "source": [
    "data = df.copy()\n",
    "data = data.drop(['screen_name', 'location', 'description'] ,axis = 1)\n",
    "print(data)\n",
    "ftr_count = len(data.keys())\n",
    "data = np.asarray(data.drop(['bot'], axis = 1))\n",
    "\n",
    "# idx =int(len(df)*.7) #70-30 split\n",
    "# X_train, X_test, Y_train, Y_test = np.array(data[:idx:]), np.array(data[idx:,:]), np.array(df.bot[:idx:]), np.array(df.bot[idx:,:])\n",
    "# X_train, X_test, Y_train, Y_test = np.array(data[:idx]), np.array(data[idx:]), np.array(df.bot[:idx]), np.array(df.bot[idx:])\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data, np.array(df.bot),test_size = 0.3, random_state = 78)\n",
    "X_train, X_test, Y_train, Y_test = X_train.astype(np.float), X_test.astype(np.float), Y_train.astype(np.float), Y_test.astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC:  0.681757656458056\n"
     ]
    }
   ],
   "source": [
    "#RANDOM FOREST\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators = 3, criterion = 'entropy')\n",
    "rf.fit(X_train, Y_train)\n",
    "y_predict_forest = rf.predict(X_test)\n",
    "y_predict_forest = [1 if i > 0.5 else 0 for i in y_predict_forest]\n",
    "print(\"ACC: \", sum([1 if i==j else 0  for i,j in zip(y_predict_forest,Y_test) ])/len(y_predict_forest))\n",
    "# print(classification_report(Y_test, y_predict_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[09:52:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"verbose\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[09:52:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "ACC:  0.7683089214380826\n"
     ]
    }
   ],
   "source": [
    "#RANDOM FOREST WITH BOOSTING\n",
    "# Import the model we are using\n",
    "from xgboost import XGBRFClassifier\n",
    "rf = XGBRFClassifier(n_estimators=100, use_label_encoder=False, verbose = True)\n",
    "rf.fit(X_train, Y_train)\n",
    "y_predict_forest = rf.predict(X_test)\n",
    "y_predict_forest = [1 if i > 0.5 else 0 for i in y_predict_forest]\n",
    "\n",
    "print(\"ACC: \", sum([1 if i==j else 0  for i,j in zip(y_predict_forest,Y_test) ])/len(y_predict_forest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC:  0.6644474034620506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=100) # tuned to 100\n",
    "knn.fit(X_train, Y_train)\n",
    "y_predict_knn = knn.predict(X_test)\n",
    "y_predict_knn = [1 if i > 0.5 else 0 for i in y_predict_knn]\n",
    "print(\"ACC: \", sum([1 if i==j else 0  for i,j in zip(y_predict_knn,Y_test) ])/len(y_predict_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                512       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32)                0         \n",
      "                                                                 \n",
      " activation (Activation)     (None, 32)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               8320      \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 32)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 33        \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21,313\n",
      "Trainable params: 21,313\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#MODELS\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      keras.metrics.FalsePositives(name='fp'),\n",
    "      keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve,\n",
    "]\n",
    "\n",
    "def create_model(idim = ftr_count-1):\n",
    "  model = Sequential()\n",
    "\n",
    "  model.add(Dense(32, input_dim=idim))\n",
    "  model.add(Dropout(.3))\n",
    "  model.add(Activation('gelu'))\n",
    "\n",
    "  model.add(Dense(64, input_dim=32))\n",
    "  model.add(Dropout(.3))\n",
    "  model.add(Activation('gelu'))\n",
    "\n",
    "  model.add(Dense(128, input_dim=64))\n",
    "  model.add(Dropout(.5))\n",
    "  model.add(Activation('gelu'))\n",
    "\n",
    "\n",
    "  model.add(Dense(64, input_dim=128))\n",
    "  model.add(Dropout(.3))\n",
    "  model.add(Activation('gelu'))\n",
    "  \n",
    "  model.add(Dense(32, input_dim=64))\n",
    "  model.add(Dropout(.1))\n",
    "  model.add(Activation('gelu'))\n",
    "\n",
    "  model.add(Dense(1, input_dim=64))\n",
    "  model.add(Activation('sigmoid'))\n",
    "\n",
    "  optimizer = tf.keras.optimizers.SGD(\n",
    "    learning_rate=1e-3, nesterov=False,\n",
    "  )\n",
    "  model.compile(optimizer = optimizer, loss= tfa.losses.SigmoidFocalCrossEntropy(),  metrics=METRICS)\n",
    "  return model\n",
    "\n",
    "\n",
    "# class_weight = compute_class_weight(class_weight = 'balanced', classes = [0,1], y = np.array(df.bot).astype(np.float))\n",
    "# class_weight = {0: class_weight[0],\n",
    "#                 1: class_weight[1]}\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-a1870534dfb0>:1: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  history = model.fit(x=X_train.astype(np.float), y=Y_train.astype(np.float), batch_size=8, epochs=50, validation_data=(X_test.astype(np.float), Y_test.astype(np.float)), verbose=1, shuffle=True, callbacks=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "193/219 [=========================>....] - ETA: 0s - loss: 0.0855 - tp: 54.0000 - fp: 92.0000 - tn: 791.0000 - fn: 607.0000 - accuracy: 0.5473 - precision: 0.3699 - recall: 0.0817 - auc: 0.4990 - prc: 0.4217               \n",
      "Epoch 00001: val_loss improved from inf to 0.07690, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 3s 5ms/step - loss: 0.0847 - tp: 54.0000 - fp: 92.0000 - tn: 914.0000 - fn: 691.0000 - accuracy: 0.5528 - precision: 0.3699 - recall: 0.0725 - auc: 0.5034 - prc: 0.4218 - val_loss: 0.0769 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5188 - val_prc: 0.4610 - lr: 0.0010\n",
      "Epoch 2/50\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.0747 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 985.0000 - fn: 735.0000 - accuracy: 0.5727 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5029 - prc: 0.4187\n",
      "Epoch 00002: val_loss improved from 0.07690 to 0.07224, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0747 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5057 - prc: 0.4188 - val_loss: 0.0722 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5833 - val_prc: 0.5294 - lr: 0.0010\n",
      "Epoch 3/50\n",
      "212/219 [============================>.] - ETA: 0s - loss: 0.0710 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 974.0000 - fn: 722.0000 - accuracy: 0.5743 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5136 - prc: 0.4365\n",
      "Epoch 00003: val_loss improved from 0.07224 to 0.07086, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0710 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5168 - prc: 0.4378 - val_loss: 0.0709 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5259 - val_prc: 0.4752 - lr: 0.0010\n",
      "Epoch 4/50\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.0697 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 989.0000 - fn: 739.0000 - accuracy: 0.5723 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5434 - prc: 0.4546\n",
      "Epoch 00004: val_loss improved from 0.07086 to 0.07048, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0696 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5468 - prc: 0.4546 - val_loss: 0.0705 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5385 - val_prc: 0.4924 - lr: 0.0010\n",
      "Epoch 5/50\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.0693 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 992.0000 - fn: 728.0000 - accuracy: 0.5767 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5231 - prc: 0.4272\n",
      "Epoch 00005: val_loss improved from 0.07048 to 0.07041, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0694 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5226 - prc: 0.4283 - val_loss: 0.0704 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5990 - val_prc: 0.5379 - lr: 0.0010\n",
      "Epoch 6/50\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.0692 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 996.0000 - fn: 732.0000 - accuracy: 0.5764 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5169 - prc: 0.4284\n",
      "Epoch 00006: val_loss improved from 0.07041 to 0.07040, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0693 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5160 - prc: 0.4310 - val_loss: 0.0704 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5524 - val_prc: 0.5043 - lr: 0.0010\n",
      "Epoch 7/50\n",
      "202/219 [==========================>...] - ETA: 0s - loss: 0.0692 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 931.0000 - fn: 685.0000 - accuracy: 0.5761 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5131 - prc: 0.4205\n",
      "Epoch 00007: val_loss did not improve from 0.07040\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0693 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5114 - prc: 0.4241 - val_loss: 0.0704 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5920 - val_prc: 0.5351 - lr: 0.0010\n",
      "Epoch 8/50\n",
      "210/219 [===========================>..] - ETA: 0s - loss: 0.0688 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 969.0000 - fn: 711.0000 - accuracy: 0.5768 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5551 - prc: 0.4554\n",
      "Epoch 00008: val_loss did not improve from 0.07040\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0689 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5553 - prc: 0.4564 - val_loss: 0.0704 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5942 - val_prc: 0.5233 - lr: 0.0010\n",
      "Epoch 9/50\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.0692 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 993.0000 - fn: 735.0000 - accuracy: 0.5747 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5180 - prc: 0.4235\n",
      "Epoch 00009: val_loss did not improve from 0.07040\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0693 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5163 - prc: 0.4217 - val_loss: 0.0704 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6017 - val_prc: 0.5408 - lr: 0.0010\n",
      "Epoch 10/50\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.0691 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1001.0000 - fn: 743.0000 - accuracy: 0.5740 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5358 - prc: 0.4415\n",
      "Epoch 00010: val_loss did not improve from 0.07040\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0690 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5358 - prc: 0.4410 - val_loss: 0.0704 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.5943 - val_prc: 0.5495 - lr: 0.0010\n",
      "Epoch 11/50\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.0689 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 998.0000 - fn: 738.0000 - accuracy: 0.5749 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5370 - prc: 0.4502\n",
      "Epoch 00011: val_loss improved from 0.07040 to 0.07040, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0690 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5365 - prc: 0.4502 - val_loss: 0.0704 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6252 - val_prc: 0.5627 - lr: 0.0010\n",
      "Epoch 12/50\n",
      "176/219 [=======================>......] - ETA: 0s - loss: 0.0692 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 803.0000 - fn: 605.0000 - accuracy: 0.5703 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5432 - prc: 0.4567\n",
      "Epoch 00012: val_loss improved from 0.07040 to 0.07038, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0690 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5362 - prc: 0.4459 - val_loss: 0.0704 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6213 - val_prc: 0.5537 - lr: 0.0010\n",
      "Epoch 13/50\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.0691 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 984.0000 - fn: 728.0000 - accuracy: 0.5748 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5343 - prc: 0.4448\n",
      "Epoch 00013: val_loss did not improve from 0.07038\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0691 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5352 - prc: 0.4458 - val_loss: 0.0704 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6148 - val_prc: 0.5514 - lr: 0.0010\n",
      "Epoch 14/50\n",
      "218/219 [============================>.] - ETA: 0s - loss: 0.0691 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1003.0000 - fn: 741.0000 - accuracy: 0.5751 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5191 - prc: 0.4314\n",
      "Epoch 00014: val_loss improved from 0.07038 to 0.07037, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0691 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5198 - prc: 0.4323 - val_loss: 0.0704 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6177 - val_prc: 0.5526 - lr: 0.0010\n",
      "Epoch 15/50\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.0689 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 992.0000 - fn: 736.0000 - accuracy: 0.5741 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5436 - prc: 0.4520\n",
      "Epoch 00015: val_loss improved from 0.07037 to 0.07034, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0689 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5434 - prc: 0.4514 - val_loss: 0.0703 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6137 - val_prc: 0.5506 - lr: 0.0010\n",
      "Epoch 16/50\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.0685 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 995.0000 - fn: 725.0000 - accuracy: 0.5785 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5640 - prc: 0.4583\n",
      "Epoch 00016: val_loss improved from 0.07034 to 0.07032, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0688 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5607 - prc: 0.4588 - val_loss: 0.0703 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6190 - val_prc: 0.5570 - lr: 0.0010\n",
      "Epoch 17/50\n",
      "202/219 [==========================>...] - ETA: 0s - loss: 0.0689 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 928.0000 - fn: 688.0000 - accuracy: 0.5743 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5476 - prc: 0.4473\n",
      "Epoch 00017: val_loss improved from 0.07032 to 0.07030, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0689 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5441 - prc: 0.4428 - val_loss: 0.0703 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6177 - val_prc: 0.5565 - lr: 0.0010\n",
      "Epoch 18/50\n",
      "195/219 [=========================>....] - ETA: 0s - loss: 0.0691 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 891.0000 - fn: 669.0000 - accuracy: 0.5712 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5473 - prc: 0.4527\n",
      "Epoch 00018: val_loss improved from 0.07030 to 0.07028, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0690 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5415 - prc: 0.4446 - val_loss: 0.0703 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6172 - val_prc: 0.5538 - lr: 0.0010\n",
      "Epoch 19/50\n",
      "217/219 [============================>.] - ETA: 0s - loss: 0.0687 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 998.0000 - fn: 738.0000 - accuracy: 0.5749 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5647 - prc: 0.4698\n",
      "Epoch 00019: val_loss improved from 0.07028 to 0.07025, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0687 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5646 - prc: 0.4695 - val_loss: 0.0702 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6177 - val_prc: 0.5584 - lr: 0.0010\n",
      "Epoch 20/50\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.0686 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 993.0000 - fn: 727.0000 - accuracy: 0.5773 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5570 - prc: 0.4595\n",
      "Epoch 00020: val_loss improved from 0.07025 to 0.07022, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0688 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5570 - prc: 0.4631 - val_loss: 0.0702 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6234 - val_prc: 0.5685 - lr: 0.0010\n",
      "Epoch 21/50\n",
      "215/219 [============================>.] - ETA: 0s - loss: 0.0687 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 996.0000 - fn: 724.0000 - accuracy: 0.5791 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5583 - prc: 0.4592\n",
      "Epoch 00021: val_loss improved from 0.07022 to 0.07020, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0689 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5578 - prc: 0.4639 - val_loss: 0.0702 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6253 - val_prc: 0.5698 - lr: 0.0010\n",
      "Epoch 22/50\n",
      "199/219 [==========================>...] - ETA: 0s - loss: 0.0686 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 923.0000 - fn: 669.0000 - accuracy: 0.5798 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5506 - prc: 0.4468\n",
      "Epoch 00022: val_loss improved from 0.07020 to 0.07019, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0689 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5467 - prc: 0.4496 - val_loss: 0.0702 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6239 - val_prc: 0.5685 - lr: 0.0010\n",
      "Epoch 23/50\n",
      "214/219 [============================>.] - ETA: 0s - loss: 0.0688 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 977.0000 - fn: 735.0000 - accuracy: 0.5707 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5721 - prc: 0.4863\n",
      "Epoch 00023: val_loss improved from 0.07019 to 0.07018, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0686 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5735 - prc: 0.4835 - val_loss: 0.0702 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6293 - val_prc: 0.6039 - lr: 0.0010\n",
      "Epoch 24/50\n",
      "207/219 [===========================>..] - ETA: 0s - loss: 0.0689 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 947.0000 - fn: 709.0000 - accuracy: 0.5719 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5732 - prc: 0.4717\n",
      "Epoch 00024: val_loss improved from 0.07018 to 0.07016, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0688 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5690 - prc: 0.4647 - val_loss: 0.0702 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6243 - val_prc: 0.5675 - lr: 0.0010\n",
      "Epoch 25/50\n",
      "213/219 [============================>.] - ETA: 0s - loss: 0.0687 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 983.0000 - fn: 721.0000 - accuracy: 0.5769 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5679 - prc: 0.4640\n",
      "Epoch 00025: val_loss improved from 0.07016 to 0.07013, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0688 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5693 - prc: 0.4684 - val_loss: 0.0701 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6277 - val_prc: 0.5705 - lr: 0.0010\n",
      "Epoch 26/50\n",
      "184/219 [========================>.....] - ETA: 0s - loss: 0.0682 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 861.0000 - fn: 611.0000 - accuracy: 0.5849 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5772 - prc: 0.4694\n",
      "Epoch 00026: val_loss improved from 0.07013 to 0.07010, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0687 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5760 - prc: 0.4792 - val_loss: 0.0701 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6336 - val_prc: 0.5786 - lr: 0.0010\n",
      "Epoch 27/50\n",
      "212/219 [============================>.] - ETA: 0s - loss: 0.0690 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 972.0000 - fn: 724.0000 - accuracy: 0.5731 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5532 - prc: 0.4695\n",
      "Epoch 00027: val_loss improved from 0.07010 to 0.07009, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0689 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5520 - prc: 0.4661 - val_loss: 0.0701 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6357 - val_prc: 0.5781 - lr: 0.0010\n",
      "Epoch 28/50\n",
      "197/219 [=========================>....] - ETA: 0s - loss: 0.0686 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 902.0000 - fn: 674.0000 - accuracy: 0.5723 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5835 - prc: 0.4731\n",
      "Epoch 00028: val_loss improved from 0.07009 to 0.07007, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0686 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5790 - prc: 0.4682 - val_loss: 0.0701 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6369 - val_prc: 0.5818 - lr: 0.0010\n",
      "Epoch 29/50\n",
      "186/219 [========================>.....] - ETA: 0s - loss: 0.0687 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 850.0000 - fn: 638.0000 - accuracy: 0.5712 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5833 - prc: 0.4872\n",
      "Epoch 00029: val_loss improved from 0.07007 to 0.07005, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0686 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5761 - prc: 0.4740 - val_loss: 0.0701 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6376 - val_prc: 0.5843 - lr: 0.0010\n",
      "Epoch 30/50\n",
      "200/219 [==========================>...] - ETA: 0s - loss: 0.0687 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 922.0000 - fn: 678.0000 - accuracy: 0.5763 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5688 - prc: 0.4746\n",
      "Epoch 00030: val_loss improved from 0.07005 to 0.07004, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0688 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5664 - prc: 0.4721 - val_loss: 0.0700 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6382 - val_prc: 0.5820 - lr: 0.0010\n",
      "Epoch 31/50\n",
      "213/219 [============================>.] - ETA: 0s - loss: 0.0686 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 973.0000 - fn: 731.0000 - accuracy: 0.5710 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5955 - prc: 0.4889\n",
      "Epoch 00031: val_loss improved from 0.07004 to 0.07001, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0684 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5940 - prc: 0.4857 - val_loss: 0.0700 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6449 - val_prc: 0.5935 - lr: 0.0010\n",
      "Epoch 32/50\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.0688 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 971.0000 - fn: 717.0000 - accuracy: 0.5752 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5532 - prc: 0.4515\n",
      "Epoch 00032: val_loss improved from 0.07001 to 0.06999, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0689 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5547 - prc: 0.4555 - val_loss: 0.0700 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6538 - val_prc: 0.6074 - lr: 0.0010\n",
      "Epoch 33/50\n",
      "205/219 [===========================>..] - ETA: 0s - loss: 0.0683 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 945.0000 - fn: 695.0000 - accuracy: 0.5762 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5884 - prc: 0.5007\n",
      "Epoch 00033: val_loss improved from 0.06999 to 0.06997, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0685 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5841 - prc: 0.4941 - val_loss: 0.0700 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6491 - val_prc: 0.6031 - lr: 0.0010\n",
      "Epoch 34/50\n",
      "216/219 [============================>.] - ETA: 0s - loss: 0.0685 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 997.0000 - fn: 731.0000 - accuracy: 0.5770 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5688 - prc: 0.4723\n",
      "Epoch 00034: val_loss improved from 0.06997 to 0.06995, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0687 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5663 - prc: 0.4745 - val_loss: 0.0699 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6510 - val_prc: 0.6058 - lr: 0.0010\n",
      "Epoch 35/50\n",
      "203/219 [==========================>...] - ETA: 0s - loss: 0.0687 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 932.0000 - fn: 692.0000 - accuracy: 0.5739 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5731 - prc: 0.4687\n",
      "Epoch 00035: val_loss improved from 0.06995 to 0.06994, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0686 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5776 - prc: 0.4720 - val_loss: 0.0699 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6539 - val_prc: 0.6073 - lr: 0.0010\n",
      "Epoch 36/50\n",
      "219/219 [==============================] - ETA: 0s - loss: 0.0686 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5669 - prc: 0.4819\n",
      "Epoch 00036: val_loss improved from 0.06994 to 0.06990, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0686 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5669 - prc: 0.4819 - val_loss: 0.0699 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6513 - val_prc: 0.6059 - lr: 0.0010\n",
      "Epoch 37/50\n",
      "187/219 [========================>.....] - ETA: 0s - loss: 0.0692 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 842.0000 - fn: 654.0000 - accuracy: 0.5628 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5812 - prc: 0.4949\n",
      "Epoch 00037: val_loss improved from 0.06990 to 0.06988, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0685 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5875 - prc: 0.4928 - val_loss: 0.0699 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6520 - val_prc: 0.6056 - lr: 0.0010\n",
      "Epoch 38/50\n",
      "186/219 [========================>.....] - ETA: 0s - loss: 0.0682 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 862.0000 - fn: 626.0000 - accuracy: 0.5793 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5996 - prc: 0.5023\n",
      "Epoch 00038: val_loss improved from 0.06988 to 0.06985, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0684 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5961 - prc: 0.5015 - val_loss: 0.0698 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6515 - val_prc: 0.5980 - lr: 0.0010\n",
      "Epoch 39/50\n",
      "185/219 [========================>.....] - ETA: 0s - loss: 0.0685 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 839.0000 - fn: 641.0000 - accuracy: 0.5669 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6119 - prc: 0.5123\n",
      "Epoch 00039: val_loss improved from 0.06985 to 0.06983, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0681 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6190 - prc: 0.5119 - val_loss: 0.0698 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6544 - val_prc: 0.6079 - lr: 0.0010\n",
      "Epoch 40/50\n",
      "201/219 [==========================>...] - ETA: 0s - loss: 0.0686 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 919.0000 - fn: 689.0000 - accuracy: 0.5715 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5813 - prc: 0.4829\n",
      "Epoch 00040: val_loss improved from 0.06983 to 0.06981, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0685 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5775 - prc: 0.4794 - val_loss: 0.0698 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6555 - val_prc: 0.6062 - lr: 0.0010\n",
      "Epoch 41/50\n",
      "195/219 [=========================>....] - ETA: 0s - loss: 0.0678 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 923.0000 - fn: 637.0000 - accuracy: 0.5917 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5712 - prc: 0.4517\n",
      "Epoch 00041: val_loss improved from 0.06981 to 0.06977, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0686 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5698 - prc: 0.4690 - val_loss: 0.0698 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6466 - val_prc: 0.5884 - lr: 0.0010\n",
      "Epoch 42/50\n",
      "195/219 [=========================>....] - ETA: 0s - loss: 0.0682 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 898.0000 - fn: 662.0000 - accuracy: 0.5756 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5945 - prc: 0.4915\n",
      "Epoch 00042: val_loss improved from 0.06977 to 0.06975, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0682 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5965 - prc: 0.4958 - val_loss: 0.0697 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6464 - val_prc: 0.5894 - lr: 0.0010\n",
      "Epoch 43/50\n",
      "199/219 [==========================>...] - ETA: 0s - loss: 0.0683 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 912.0000 - fn: 680.0000 - accuracy: 0.5729 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5982 - prc: 0.5156\n",
      "Epoch 00043: val_loss improved from 0.06975 to 0.06972, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0683 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5919 - prc: 0.5046 - val_loss: 0.0697 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6471 - val_prc: 0.5897 - lr: 0.0010\n",
      "Epoch 44/50\n",
      "190/219 [=========================>....] - ETA: 0s - loss: 0.0683 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 875.0000 - fn: 645.0000 - accuracy: 0.5757 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5852 - prc: 0.4847\n",
      "Epoch 00044: val_loss improved from 0.06972 to 0.06970, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0684 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5870 - prc: 0.4826 - val_loss: 0.0697 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6506 - val_prc: 0.5967 - lr: 0.0010\n",
      "Epoch 45/50\n",
      "213/219 [============================>.] - ETA: 0s - loss: 0.0679 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 984.0000 - fn: 720.0000 - accuracy: 0.5775 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6154 - prc: 0.5183\n",
      "Epoch 00045: val_loss improved from 0.06970 to 0.06967, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0680 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6142 - prc: 0.5195 - val_loss: 0.0697 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6499 - val_prc: 0.5972 - lr: 0.0010\n",
      "Epoch 46/50\n",
      "199/219 [==========================>...] - ETA: 0s - loss: 0.0686 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 910.0000 - fn: 682.0000 - accuracy: 0.5716 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5900 - prc: 0.4967\n",
      "Epoch 00046: val_loss improved from 0.06967 to 0.06965, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0685 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5864 - prc: 0.4909 - val_loss: 0.0697 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6526 - val_prc: 0.6028 - lr: 0.0010\n",
      "Epoch 47/50\n",
      "196/219 [=========================>....] - ETA: 0s - loss: 0.0684 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 896.0000 - fn: 672.0000 - accuracy: 0.5714 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5991 - prc: 0.5012\n",
      "Epoch 00047: val_loss improved from 0.06965 to 0.06963, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0682 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5994 - prc: 0.5002 - val_loss: 0.0696 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6535 - val_prc: 0.6079 - lr: 0.0010\n",
      "Epoch 48/50\n",
      "197/219 [=========================>....] - ETA: 0s - loss: 0.0681 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 904.0000 - fn: 672.0000 - accuracy: 0.5736 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6099 - prc: 0.5139\n",
      "Epoch 00048: val_loss improved from 0.06963 to 0.06960, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0682 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.6000 - prc: 0.5026 - val_loss: 0.0696 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6642 - val_prc: 0.6296 - lr: 0.0010\n",
      "Epoch 49/50\n",
      "204/219 [==========================>...] - ETA: 0s - loss: 0.0683 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 938.0000 - fn: 694.0000 - accuracy: 0.5748 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5971 - prc: 0.4993\n",
      "Epoch 00049: val_loss improved from 0.06960 to 0.06956, saving model to ./ckpts/best_val_loss.hdf5\n",
      "\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0684 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5924 - prc: 0.4941 - val_loss: 0.0696 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6523 - val_prc: 0.6075 - lr: 0.0010\n",
      "Epoch 50/50\n",
      "211/219 [===========================>..] - ETA: 0s - loss: 0.0686 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 969.0000 - fn: 719.0000 - accuracy: 0.5741 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5785 - prc: 0.4891\n",
      "Epoch 00050: val_loss improved from 0.06956 to 0.06956, saving model to ./ckpts/best_val_loss.hdf5\n",
      "219/219 [==============================] - 0s 2ms/step - loss: 0.0685 - tp: 0.0000e+00 - fp: 0.0000e+00 - tn: 1006.0000 - fn: 745.0000 - accuracy: 0.5745 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.5829 - prc: 0.4920 - val_loss: 0.0696 - val_tp: 0.0000e+00 - val_fp: 0.0000e+00 - val_tn: 407.0000 - val_fn: 344.0000 - val_accuracy: 0.5419 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.6528 - val_prc: 0.6079 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "\n",
    "history = model.fit(x=X_train.astype(np.float), y=Y_train.astype(np.float), batch_size=8, epochs=50, validation_data=(X_test.astype(np.float), Y_test.astype(np.float)), verbose=1, shuffle=True, callbacks=\n",
    "                                [ModelCheckpoint(filepath='./ckpts/best_val_loss.hdf5',\n",
    "                                               monitor= 'val_loss',\n",
    "                                               save_best_only=True,\n",
    "                                               mode='auto',\n",
    "                                               save_weights_only=True,\n",
    "                                               verbose=2),\n",
    "                                EarlyStopping(monitor='val_loss',\n",
    "                                             mode='auto',\n",
    "                                             patience=100,\n",
    "                                             verbose=1),  \n",
    "                                ReduceLROnPlateau(\n",
    "                                monitor='loss', factor=0.1, patience=10, verbose=1,\n",
    "                                mode='auto', min_delta=0.0001, cooldown=0, min_lr=0\n",
    "                            )])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[407, 344],\n",
       "       [  0,   0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history['loss']\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='val')\n",
    "pyplot.xlabel(\"Epochs\")\n",
    "pyplot.ylabel(\"Loss\")\n",
    "pyplot.title(\"Training and Validation Loss Over %d Epochs\" % (len(history.history['loss']),))\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "\n",
    "history.history['accuracy']\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='val')\n",
    "pyplot.xlabel(\"Epochs\")\n",
    "pyplot.ylabel(\"Accuracy\")\n",
    "pyplot.title(\"Training and Validation Accuracy Over %d Epochs\" % (len(history.history['loss']),))\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    " \n",
    "from sklearn.metrics import log_loss # The data is binary\n",
    "from math import sqrt\n",
    "\n",
    "model.built = True\n",
    "model.load_weights(\"ckpts/best_val_loss.hdf5\")\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = [1 if i > 0.5 else 0 for i in y_pred] # roc curve when you change threshold\n",
    "confusion_matrix(y_pred, Y_test)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cc4240bb6330fdaa0e5b1d4f2184411e5109cd7a3e886f36b28dcc715df5a2e5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('stonks': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
